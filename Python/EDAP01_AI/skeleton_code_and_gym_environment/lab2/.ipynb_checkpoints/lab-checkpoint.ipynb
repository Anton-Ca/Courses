{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with the perceptron and logistic regression\n",
    "\n",
    "__Individual assignment__\n",
    "\n",
    "Author of the assignment: Pierre Nugues\n",
    "\n",
    "__Student name__: Anton Carlsson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The objectives of this second assignment are to:\n",
    "\n",
    "1.  Write a linear regression program using gradient descent;\n",
    "2.  Write linear classifiers using the perceptron algorithm and logistic regression;\n",
    "3.  Experiment variations of the algorithms;\n",
    "4.  Evaluate your classifiers;\n",
    "5.  Experiment with popular tools;\n",
    "6.  Read a scientific article on optimization techniques and comment it;\n",
    "7.  Present your code, results, and comments in a short dissertation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The gradient descent is a basic technique to estimate linear discriminant functions. You will first use the gradient descent method to implement linear regression. You will then program the perceptron algorithm. Finally, you will improve the threshold function with the logistic curve (logistic regression). You will try various configurations and study their influence on the learning speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Programming language\n",
    "As programming language, you will use Python and write your code in this notebook.\n",
    "\n",
    "You need to have a comprehensive Python distribution such as Anaconda (https://www.anaconda.com/products/individual). This distribution is available on the student computers at the computer science department.\n",
    "Finally, you start a notebook by typing:\n",
    "\n",
    "`jupyter lab`\n",
    "\n",
    "in a terminal window and you select the notebook by clicking on it in the left pane.\n",
    "You run the pieces of code by typing shift+enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports you may use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "You will implement the gradient descent method as explained in pages 719--720 in Russell-Norvig and in the slides to compute regression lines. You will implement the stochastic and batch versions of the algorithm.\n",
    "\n",
    "You must try to do it yourself first. If you encounter difficulties, you also have the solution to this exercise in the section _Solution to linear regression_ below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation of linear regression\n",
    "You will implement a regression program to predict the counts of _A_'s in a text from the total count of letters. You will apply it on two data sets corresponding to letter counts in the 15 chapters of the French and English versions of _Salammb√¥_, where the first column is the total count of characters and the second one, the count of A's. \n",
    "\n",
    "Start with either French or English and when your program ready, test it on the other language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_fr = np.array([[36961, 2503],\n",
    "                      [43621, 2992],\n",
    "                      [15694, 1042],\n",
    "                      [36231, 2487],\n",
    "                      [29945, 2014],\n",
    "                      [40588, 2805],\n",
    "                      [75255, 5062],\n",
    "                      [37709, 2643],\n",
    "                      [30899, 2126],\n",
    "                      [25486, 1784],\n",
    "                      [37497, 2641],\n",
    "                      [40398, 2766],\n",
    "                      [74105, 5047],\n",
    "                      [76725, 5312],\n",
    "                      [18317, 1215]])\n",
    "\n",
    "stat_en = np.array([[35680, 2217],\n",
    "                      [42514, 2761],\n",
    "                      [15162, 990],\n",
    "                      [35298, 2274],\n",
    "                      [29800, 1865],\n",
    "                      [40255, 2606],\n",
    "                      [74532, 4805],\n",
    "                      [37464, 2396],\n",
    "                      [31030, 1993],\n",
    "                      [24843, 1627],\n",
    "                      [36172, 2375],\n",
    "                      [39552, 2560],\n",
    "                      [72545, 4597],\n",
    "                      [75352, 4871],\n",
    "                      [18031, 1119]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the datasets above, tell what is $\\mathbf{X}$ and $\\mathbf{y}$. Extract: X is feature vector consisting of the number of words in the first column of the dataset. Y is target, the A vector corresponding to the second column in the dataset. \n",
    "1. The $\\mathbf{X}$ matrix, where you will have a column to model the intercept;\n",
    "2. The $\\mathbf{y}$ vector\n",
    "\n",
    "from these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 35680], [1, 42514], [1, 15162], [1, 35298], [1, 29800], [1, 40255], [1, 74532], [1, 37464], [1, 31030], [1, 24843], [1, 36172], [1, 39552], [1, 72545], [1, 75352], [1, 18031]]\n",
      "[2217, 2761, 990, 2274, 1865, 2606, 4805, 2396, 1993, 1627, 2375, 2560, 4597, 4871, 1119]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "def get_Xy():\n",
    "    X = []\n",
    "    y = []\n",
    "    for el in stat_en:\n",
    "        X.append([1, el[0]])#.append(el[0])\n",
    "        y.append(el[1])\n",
    "    return X, y\n",
    "\n",
    "X,y = get_Xy()\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the arrays so that they fit in the range [0, 1] on the $x$ and $y$ axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 35680], [1, 42514], [1, 15162], [1, 35298], [1, 29800], [1, 40255], [1, 74532], [1, 37464], [1, 31030], [1, 24843], [1, 36172], [1, 39552], [1, 72545], [1, 75352], [1, 18031]]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "def get_Xy_scaled(X, y):\n",
    "    tmp = [el[1] for el in X]\n",
    "    X = [[el[0], el[1]/max(tmp)] for el in X]\n",
    "    y = [el/max(y) for el in y]\n",
    "    return X, y\n",
    "X_scaled, y_scaled = get_Xy_scaled(X, y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the descent functions. You will pass `X`, `y`, the learning rate in the $\\alpha$ variable, the initial weight vector in `w`, the tolerance in the $\\epsilon$ variable, the maximal number of epochs in `epochs`. You will return `w`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The batch size is a number of samples processed before the model is updated.\n",
    "\n",
    "- The number of epochs is the number of complete passes through the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(Xy):\n",
    "    maxima = np.amax(Xy, axis=0)\n",
    "    D = np.diag(maxima)\n",
    "    D_inv = np.linalg.inv(D)\n",
    "    Xy = Xy @ D_inv\n",
    "    return (Xy, maxima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(X, y, w):\n",
    "    error = y - X @ w\n",
    "    return error.T @ error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w):\n",
    "    return X @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def fit_batch(X, y, alpha, w,\n",
    "                  epochs=500,\n",
    "                  epsilon=1.0e-5):\n",
    "    \"\"\"\n",
    "    Batch gradient descent\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param alpha:\n",
    "    :param w:\n",
    "    :param epochs:\n",
    "    :param epsilon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global logs\n",
    "    logs = []\n",
    "    alpha /= len(X)\n",
    "    for epoch in range(epochs):\n",
    "        loss = y - predict(X, w)\n",
    "        gradient = X.T @ loss\n",
    "        w = w + alpha * gradient\n",
    "        logs += (w, alpha, sse(X, y, w))\n",
    "        if np.linalg.norm(gradient) < epsilon:\n",
    "            break\n",
    "    print(\"Epoch\", epoch)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def fit_stoch(X, y, alpha, w,\n",
    "                  epochs=500,\n",
    "                  epsilon=1.0e-5):\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param alpha:\n",
    "    :param w:\n",
    "    :param epochs:\n",
    "    :param epsilon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global logs, logs_stoch\n",
    "    logs = []\n",
    "    logs_stoch = []\n",
    "    random.seed(0)\n",
    "    idx = list(range(len(X)))\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(idx)\n",
    "        for i in idx:\n",
    "            loss = y[i] - predict(X[i], w)[0]\n",
    "            gradient = loss * np.array([X[i]]).T\n",
    "            w = w + alpha * gradient\n",
    "            logs_stoch += (w, alpha, sse(X, y, w))\n",
    "        if np.linalg.norm(gradient) < epsilon:\n",
    "            break\n",
    "        logs += (w, alpha, sse(X, y, w))\n",
    "    print(\"Epoch\", epoch)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying batch descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the batch descent and print the final weight values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_Xy()\n",
    "X_scaled,y_scaled = get_Xy_scaled(X, y)\n",
    "normalized = True\n",
    "debug = False\n",
    "# Predictors\n",
    "X_scaled = np.array(X_scaled)\n",
    "# Response\n",
    "y_scaled = np.array([y_scaled]).T\n",
    "\n",
    "alpha = 1.0\n",
    "#if normalized:\n",
    "#    X_scaled, maxima_X = normalize(X_scaled)\n",
    "#    y_scaled, maxima_y = normalize(y_scaled)\n",
    "#    maxima = np.concatenate((maxima_X, maxima_y))\n",
    "    #alpha = 1.0\n",
    "#    print(\"-Normalized-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Batch descent===\n",
      "Epoch 235\n",
      "Weights [[-7.31744724e-04]\n",
      " [ 9.94697306e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "print(\"===Batch descent===\")\n",
    "w_batch = np.zeros(X_scaled.shape[1]).reshape((-1, 1))\n",
    "#alpha = 0.000001\n",
    "w_batch = fit_batch(X_scaled, y_scaled, alpha, w_batch)\n",
    "print(\"Weights\", w_batch)\n",
    "#print(\"SSE\", sse(X_scaled, y_scaled, w_batch))\n",
    "#if normalized:\n",
    "#    maxima = maxima.reshape(-1, 1)\n",
    "#    w = maxima[-1, 0] * (w_batch / maxima[:-1, 0:1])\n",
    "#    print(\"Restored weights\", w_batch)\n",
    "if debug:\n",
    "    print(\"Logs\", logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the points of your dataset as well as the regression lines you obtain using matplotlib or another similar program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linspace: \n",
      " [0.20121563 0.25827165 0.31532768 0.37238371 0.42943973 0.48649576\n",
      " 0.54355179 0.60060781 0.65766384 0.71471987 0.77177589 0.82883192\n",
      " 0.88588795 0.94294397 1.        ]\n",
      "\n",
      "weights: \n",
      " [[-7.31744724e-04]\n",
      " [ 9.94697306e-01]]\n",
      "\n",
      "\n",
      "y=kx+m: \n",
      " [0.99435082 0.99428445 0.99455007 0.99435453 0.99440792 0.99430639\n",
      " 0.99397352 0.99433349 0.99439597 0.99445606 0.99434604 0.99431322\n",
      " 0.99399282 0.99396556 0.99452221]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test = [X_scaled[i][1] for i in range(len(X_scaled))]\n",
    "y_test = [yi for yi in y_scaled]\n",
    "lin = np.linspace(min(x_test),\n",
    "               max(x_test),\n",
    "               num = len(X_scaled),\n",
    "               endpoint = True)\n",
    "#x_test = np.array(x_test)\n",
    "#x_test = x_test.reshape(-1, 1)\n",
    "print('linspace: \\n {}'.format(lin))\n",
    "print()\n",
    "print('weights: \\n {}'.format(w_batch))\n",
    "print()\n",
    "#print(y_test .* x_test)\n",
    "print()\n",
    "#print(np.matrix(x_test) + np.matrix(x_test * w_batch))\n",
    "\n",
    "\n",
    "print('y=kx+m: \\n {}'.format(w_batch[0]*x_test + w_batch[1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.plot(lin, \n",
    "            w_batch[1]*lin + w_batch[0],\n",
    "            'g', label='batch')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Stochastic descent===\n",
      "Epoch 499\n",
      "Weights [[0.00339067]\n",
      " [0.99373072]]\n",
      "SSE [[0.00105848]]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "print(\"===Stochastic descent===\")\n",
    "w_stoch = np.zeros(X_scaled.shape[1]).reshape((-1, 1))\n",
    "w_stoch = fit_stoch(X_scaled, y_scaled, alpha, w_stoch)\n",
    "print(\"Weights\", w_stoch)\n",
    "print(\"SSE\", sse(X_scaled, y_scaled, w_stoch))\n",
    "#if normalized:\n",
    "#    maxima = maxima.reshape(-1, 1)\n",
    "#    w = maxima[-1, 0] * (w / maxima[:-1, 0:1])\n",
    "#    print(\"Restored weights\", w)\n",
    "if debug:\n",
    "    print(\"Logs\", logs)\n",
    "    print(\"Logs stoch.\", logs_stoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the points of your dataset as well as the regression lines you obtain using matplotlib or another similar program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linspace: \n",
      " [0.20121563 0.25827165 0.31532768 0.37238371 0.42943973 0.48649576\n",
      " 0.54355179 0.60060781 0.65766384 0.71471987 0.77177589 0.82883192\n",
      " 0.88588795 0.94294397 1.        ]\n",
      "\n",
      "weights: \n",
      " [[0.00339067]\n",
      " [0.99373072]]\n",
      "\n",
      "\n",
      "y=kx+m: \n",
      " [0.99533624 0.99564375 0.99441297 0.99531905 0.99507165 0.9955421\n",
      " 0.99708449 0.99541651 0.995127   0.9948486  0.99535838 0.99551047\n",
      " 0.99699508 0.99712139 0.99454207]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "x_test = [X_scaled[i][1] for i in range(len(X_scaled))]\n",
    "y_test = [yi for yi in y_scaled]\n",
    "lin = np.linspace(min(x_test),\n",
    "               max(x_test),\n",
    "               num = len(X_scaled),\n",
    "               endpoint = True)\n",
    "#x_test = np.array(x_test)\n",
    "#x_test = x_test.reshape(-1, 1)\n",
    "print('linspace: \\n {}'.format(lin))\n",
    "print()\n",
    "print('weights: \\n {}'.format(w_stoch))\n",
    "print()\n",
    "#print(y_test .* x_test)\n",
    "print()\n",
    "#print(np.matrix(x_test) + np.matrix(x_test * w_stoch))\n",
    "\n",
    "\n",
    "print('y=kx+m: \\n {}'.format(w_stoch[0]*x_test + w_stoch[1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x_test, y_test)\n",
    "plt.plot(lin, \n",
    "            w_stoch[1]*lin + w_stoch[0],\n",
    "            'g', label='stoch')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A solution to linear regression\n",
    "\n",
    "To help you start this assignment, your instructor wrote two Python notebooks that solve this exercise on linear regression. You can find them here: https://github.com/pnugues/ilppp/tree/master/programs/ch04/python\n",
    "The first notebook, `gradient_descent.ipynb`, only uses Python and vector operations such as the dot product that are in the `vector.py` file.\n",
    "The second notebook, `gradient_descent_numpy.ipynb`, uses Numpy. It is more compact, but you need to know a bit of numpy.\n",
    "\n",
    "To run these programs, download them on your computer as well as the other program in the import list: vector.py\n",
    "\n",
    "The programs are also available as Python programs from\n",
    "https://github.com/pnugues/ilppp/tree/master/programs/ch04/python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "You will use the same data set as for linear regression, but this time to classify a chapter as French or English. Given a pair of numbers corresponding the letter count and count of _A_, you will predict the language:\n",
    "1. $\\mathbf{x} = (35680, 2217)$ $\\to$ $y$ = English\n",
    "2. $\\mathbf{x} = (37497, 2641)$ $\\to$ $y$ = French"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "You will use the arrays below:\n",
    "1. `X` contains the counts of letters and of _A_ s as well as a column of ones for the intercept;\n",
    "2. `y` contains the classes, where 0 is for English and 1 for French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1.0, 35680.0, 2217.0],\n",
    "     [1.0, 42514.0, 2761.0],\n",
    "     [1.0, 15162.0, 990.0],\n",
    "     [1.0, 35298.0, 2274.0],\n",
    "     [1.0, 29800.0, 1865.0],\n",
    "     [1.0, 40255.0, 2606.0],\n",
    "     [1.0, 74532.0, 4805.0],\n",
    "     [1.0, 37464.0, 2396.0],\n",
    "     [1.0, 31030.0, 1993.0],\n",
    "     [1.0, 24843.0, 1627.0],\n",
    "     [1.0, 36172.0, 2375.0],\n",
    "     [1.0, 39552.0, 2560.0],\n",
    "     [1.0, 72545.0, 4597.0],\n",
    "     [1.0, 75352.0, 4871.0],\n",
    "     [1.0, 18031.0, 1119.0],\n",
    "     [1.0, 36961.0, 2503.0],\n",
    "     [1.0, 43621.0, 2992.0],\n",
    "     [1.0, 15694.0, 1042.0],\n",
    "     [1.0, 36231.0, 2487.0],\n",
    "     [1.0, 29945.0, 2014.0],\n",
    "     [1.0, 40588.0, 2805.0],\n",
    "     [1.0, 75255.0, 5062.0],\n",
    "     [1.0, 37709.0, 2643.0],\n",
    "     [1.0, 30899.0, 2126.0],\n",
    "     [1.0, 25486.0, 1784.0],\n",
    "     [1.0, 37497.0, 2641.0],\n",
    "     [1.0, 40398.0, 2766.0],\n",
    "     [1.0, 74105.0, 5047.0],\n",
    "     [1.0, 76725.0, 5312.0],\n",
    "     [1.0, 18317.0, 1215.0]]\n",
    "y = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "     1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fr = [x[1] for i, x in enumerate(X) if y[i] == 1]\n",
    "y_fr = [x[2] for i, x in enumerate(X) if y[i] == 1]\n",
    "x_en = [x[1] for i, x in enumerate(X) if y[i] == 0]\n",
    "y_en = [x[2] for i, x in enumerate(X) if y[i] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x116fbad00>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_fr, y_fr, color='red')\n",
    "plt.scatter(x_en, y_en, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent algorithms can be very sensitive to the range. Therefore, we normalize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(observations):\n",
    "    maxima = [max([obs[i] for obs in observations]) for i in range(len(observations[0]))]\n",
    "    return ([[obs[i] / maxima[i]\n",
    "              for i in range(len(observations[0]))] for obs in observations],\n",
    "            maxima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.4650374714890844, 0.4173569277108434],\n",
       " [1.0, 0.5541088302378625, 0.5197665662650602],\n",
       " [1.0, 0.19761485826001954, 0.18637048192771086],\n",
       " [1.0, 0.460058651026393, 0.42808734939759036],\n",
       " [1.0, 0.3884001303356142, 0.3510918674698795],\n",
       " [1.0, 0.5246660149885957, 0.49058734939759036],\n",
       " [1.0, 0.9714173998044966, 0.9045557228915663],\n",
       " [1.0, 0.4882893450635386, 0.4510542168674699],\n",
       " [1.0, 0.4044314108830238, 0.37518825301204817],\n",
       " [1.0, 0.32379276637341153, 0.30628765060240964],\n",
       " [1.0, 0.47144998370804825, 0.4471009036144578],\n",
       " [1.0, 0.5155034213098729, 0.4819277108433735],\n",
       " [1.0, 0.9455197132616487, 0.8653990963855421],\n",
       " [1.0, 0.9821049201694363, 0.916980421686747],\n",
       " [1.0, 0.2350081459758879, 0.21065512048192772],\n",
       " [1.0, 0.48173346366894754, 0.4711972891566265],\n",
       " [1.0, 0.5685369827305311, 0.5632530120481928],\n",
       " [1.0, 0.2045487129358097, 0.19615963855421686],\n",
       " [1.0, 0.47221896383186707, 0.46818524096385544],\n",
       " [1.0, 0.39028999674160963, 0.37914156626506024],\n",
       " [1.0, 0.5290061909416748, 0.5280496987951807],\n",
       " [1.0, 0.9808406647116324, 0.9529367469879518],\n",
       " [1.0, 0.49148256761159986, 0.4975527108433735],\n",
       " [1.0, 0.40272401433691757, 0.4002259036144578],\n",
       " [1.0, 0.3321733463668948, 0.3358433734939759],\n",
       " [1.0, 0.4887194525904203, 0.4971762048192771],\n",
       " [1.0, 0.5265298142717497, 0.5207078313253012],\n",
       " [1.0, 0.9658520690778756, 0.9501129518072289],\n",
       " [1.0, 1.0, 1.0],\n",
       " [1.0, 0.23873574454219615, 0.22872740963855423]]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm, maxima = normalize(X)\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Perceptron\n",
    "\n",
    "1. Write the perceptron program as explained in pages 723--725 in Russell-Norvig and in the slides and run it on your data set. As suggested program structure, use two functions: \n",
    " * `fit(X, y)` that will return `w` (the model). You can choose a stochastic or batch variant;\n",
    " * `predict(X, w)` that will return `y_hat`. You can encapsulate these functions in a class and, of course, add more parameters.\n",
    "2. As a stop criterion, you will use the number of misclassified examples.\n",
    "3. You will report the parameters you have used and the weight vector\n",
    "\n",
    "You can use numpy or not. The next cells are just suggested steps. You can implement it your way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `predict(X, w)` function\n",
    "Write a `predict(X, w)` function that given a matrix of observations $\\mathbf{X}$ and a weight vector $\\mathbf{w}$ will return a $\\mathbf{\\hat{y}}$ vector classes (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def activation_func(X):\n",
    "    return np.where(X > 0.5, 1, 0) # 1 if true, 0 if false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def predict2(X, w):\n",
    "    linear_func = np.dot(X, w) #+ b \n",
    "    y_predict = activation_func(linear_func)\n",
    "    return y_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `fit(X, y)` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `fit(X, y)` function that given a matrix of observations $\\mathbf{X}$ and a vector of responses $\\mathbf{y}$ will return a weight $\\mathbf{w}$ vector. You may use the other arguments of the function, notably the number of misclassified examples to define the stop condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "#import random\n",
    "#import vector\n",
    "def fit_stoch(X, y,\n",
    "              epochs=1000,\n",
    "              max_misclassified=5,\n",
    "              verbose=True):\n",
    "    n_samples, n_features = np.array(X).shape\n",
    "    w = np.zeros(n_features)\n",
    "    alpha = 0.01 \n",
    "    y_fail = 0\n",
    "    y_pred = np.zeros(len(y))\n",
    "    for epoch in range(epochs):\n",
    "        indices = list(range(len(X)))\n",
    "        random.shuffle(indices)\n",
    "        for idx in indices:\n",
    "            xi = X[idx]\n",
    "            y_pred[idx] = predict2(xi, w)\n",
    "            gradient = alpha * (y[idx] - y_pred[idx]) #* np.array(xi).T\n",
    "            w = w + np.dot(gradient, np.array(xi))\n",
    "            \n",
    "        y_fail= sum(abs(y - y_pred))\n",
    "        if y_fail <= max_misclassified:\n",
    "            break\n",
    "        \n",
    "    print(\"Epochs:\", epoch, 'Weights: ', w)\n",
    "    print('y_fail: {}'.format(y_fail))\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 33 Weights:  [ 0.5        -0.04093829  0.04247176]\n",
      "y_fail: 4.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deVxVdf7H8ddHXMklE9tUJCdL09YhtWxaNU0rbSrN0RktJ0AxKycnS6e0pN0yc6V1/A2No42l4paVS+WSpC0umabilrkviRvw/f1x0UECAeXcA9z38/Hgwb3nfO/lcwR58z3f8z1fc84hIiKhq4zfBYiIiL8UBCIiIU5BICIS4hQEIiIhTkEgIhLiyvpdQGFFRES4qKgov8sQESlRvv766x3OuZq57StxQRAVFUVKSorfZYiIlChmlprXPp0aEhEJcQoCEZEQpyAQEQlxCgIRkRCnIBARCXEKAhGREKcgEBEJcZ4FgZm9Y2bbzGxZHvvNzIaZ2Roz+87MrvKqFhERyZuXPYL3gNYn2X8bUD/rIwYY5WEtIiIlS1ISREVBmTKBz0lJnn0pz4LAOTcP2HWSJu2AsS5gIXCmmZ3nVT0iIiVGUhLExEBqKjgX+BwT41kY+DlGUAvYmO35pqxtIiKhrX9/SEs7cVtaWmC7B0rEYLGZxZhZipmlbN++3e9yRES8tWFD4bafJj+DYDNQJ9vz2lnbfsM5l+ici3bORdesmevN80RESo/IyMJtP01+BsFk4C9ZVw81A/Y65372sR4RkeIhIQHCw0/cFh4e2O4Bz25DbWb/Bm4EIsxsE/A0UA7AOTcamAa0AdYAacD9XtUiIlKidO4c+Ny/f+B0UGRkIASObS9i5pzz5I29Eh0d7bQegYhI4ZjZ18656Nz2lYjBYhGRUJTpMlny8xLPv46CQEQkmHKbKJbLtu9++Y7m7zTn2revJXVPnouLFYkSt1SliEiJdWyi2LE5Aqmp8MADgUljR48CcGBLKs8kdWPImkyqh5/Fm3e8SWQ1b64WOkZBICISLLlNFDty5PjDafWhZ1tIPTOd7j9W5sU3f6BGeA3Py1IQiIgESx4TwrZUgYdbwweNoOF2mPcO/GHjAUjyPgRAQSAiEjyRkYHTQVkyDEZHwxMt4EgYDP4U+s6H8hlAXW9PB2WnwWIRkWDJNlHsm3Phmr9Cr7bQbLOxbCT0/zwrBDycPJYbBYGISLB07syvo4fx2D1ViY6B1LPK8P45PZnZciwXVqkLZlC3LiQmejZ5LDcKAhGRIJmyagqX7BjEkMb7eCD6QX54eged4kbwvnUhivWUIZMo1pNE8EIANEYgIuK5Tfs28fCMh5m4ciKNajbii/u/oHlkcyD3K0pjYgKPg9UpUI9ARMQjGZkZDFs0jIYjGjJ99XSev+V5lsQuoXlk8+NzyLp0CerSA7lSj0BExANLfl5CbHIsKVtSaPW7VoxsO5J61esBv+0F5MajpQdypSAQESlC+w/v56nZTzHsq2GcfcbZjLt7HB0adcDMjrfJbV5ZTh4tPZArBYGISBGZ9MMkek3vxeZ9m4mLjuO5W57jzIpn/qZdfn/tB/nqUY0RiIicro17N9J+XHva/6c9Z1U6i/nd5zOy7chcQwBO/te+D1ePKghERE5VemY6ry14jYYjGvLxTx/zYosXSXkwhWa1m530dXktQPavf8H69cENAdCpIRGRU5KyJYWYKTEs3bqUNvXbMKLNCKLOjCrQa4O8AFm+FAQiIoWw7/A+Bnw2gBGLR3DOGecw4d4J3N3w7hMGgwuic2f/fvHnpFNDIiIF4Jzjvyv+S8MRDRn+1XB6RvdkZfxK7rnknlxDILf1Z4or9QhERPKxfs96ek3rxdTVU7ni3Cv4sOOHNKnVJM/2xWG2cGGoRyAikoejGUd5Zf4rNBrZiNnrZzPk1iEsfnDxSUMAcp8nEOzZwoWhHoGISC4WblpIbHIs3/3yHXdcdAfD2wwv8JKRec0TCOZs4cJQj0BEJJs9h/bQc2pPrn37Wnam7WRih4lMum9SodYNzmueQDBnCxeGgkBEhMBg8Pjl42k4oiFjvh5D76a9WRm/krsa3lXoK4LymicQzNnChaFTQyIS8tbtXkfPaT2ZsWYGV513FVM6TSH6/OhTfr/iNk8gPwoCEQlZRzOO8uqCVxk0dxBhZcIY2moo8U3iKVvm9H81Fqd5AvlREIhISJq/cT6xybEs27aMuxrcxbDbhlG7am2/y/KFgkBEQsrug7vp90k/EpckUqdqHT7q+BHtGrTzuyxfKQhEJCQ45xi3bByPzHyEHWk7eLTZowy6cRBVKlTxuzTfKQhEpNT7addP9Jjag1lrZxF9fjTTO0/nqvOu8rusYsPTy0fNrLWZrTKzNWbWL5f9kWY228yWmtl3ZtbGy3pEJLQcyThCwrwEGo9qzMJNC3njtjdY2H2hQiAHz3oEZhYGjABaApuAxWY22Tm3IluzAcB459woM7sEmAZEeVWTiISOz1M/JzY5lpU7AjeGG9pqKLWq1vK7rGLJyx5BE2CNc26tc+4IMA7IOSLjgKpZj6sBWzysR0RCwK6Du/jr5L9y/XvXc+DoAaZ0msKEeycoBE7CyzGCWsDGbM83AU1ztBkIfGxmDwFnAC08rEdESjHnHEnfJ9FnZh92HdxF32v78vQNT3NG+TP8Lq3Y83uwuBPwnnNuiJldA/yfmTV2zmVmb2RmMUAMQGRxvVmHiPjmx50/0nNqTz5d9ylNazVl1p9ncfm5l/tdVonh5amhzUCdbM9rZ23LrjswHsA5twCoCETkfCPnXKJzLto5F12zZk2PyhWRkuZw+mGenfssl426jJQtKYxsM5IvH/hSIVBIXvYIFgP1zewCAgFwH/CnHG02ALcA75lZQwJBsN3DmkSklJi7fi6xybGs2rmKjo068lqr1zivynl+l1UieRYEzrl0M+sFzATCgHecc8vN7BkgxTk3Gfgb8KaZPUpg4Libc855VZOIlHw70nbQd1Zf3vvmPaLOjGLan6ZxW/3b/C6rRPN0jMA5N43AJaHZtz2V7fEKoLmXNYhI6eCcY+y3Y/nbx39j7+G9PN78cZ664SnCy4Xn/2I5Kb8Hi0VE8rVqxyripsYxZ/0crql9DWNuH8Ol51zqd1mlhoJARIqtQ+mHeOGLF3j+i+cJLxfO6LajefD3D1LGtKZWUVIQiEixNHvdbOKmxvHjzh/p1LgTr7Z6lXMrn+t3WaWSgkBEipXtB7bz2KzHGPvtWOpVr8fMLjO59Xe3+l1WqaYgEJFiwTnHu9+8S99Zfdl3eB9PXvckA64fQKVylfwurdRTEIiI71ZuX0nc1Djmpc7jusjrGN12NI3ObuR3WSFDQSAivjl49CAJnyfw0pcvUbl8Zd664y3uv/J+DQYHmYJARHzxydpP6DG1B2t2raHLZV0YcusQzj7jbL/LCkkKAhEJql9+/YU+H/fh/e/f58KzLmTWn2fRop5uPOwnBYGIBEWmy+TtJW/z90/+zoEjB3jq+qd44g9PULFsRb9LC3kKAhHx3LJty4hLjuPLjV9yfd3rGXP7GBpENPC7LMmiIBARz6QdTWPwvMG8PP9lqlWoxrvt3qXr5V0xM79Lk2wUBCLiiRlrZtBzak/W7VlHtyu68XLLl4kI/81yI1IMKAhEpEht/XUrj858lHHLxnFxjYuZ3XU2N0bd6HdZchIKAhEpEpkuk8SvE+n3ST8Oph9k0I2DeLz541QoW8Hv0iQfCgIROW3f//I9MckxLNy0kJsvuJlRbUdxUY2L/C5LCkhBICKn7MCRAzwz9xmGLBhC9UrVGdt+LF0u66LB4BJGQSAip2Ta6mnET4tn/Z71dL+yOy+2eJEa4TX8LktOgYJARAply/4tPDLjESasmEDDiIbM6zaPP9T9g99lyWlQEIhIgWRkZjA6ZTRPfvYkh9MPM/imwfRt3pfyYeX9Lk1Ok4JARPL17dZviU2OZdHmRbSs15KRbUdy4VkX+l2WFBEFgYjk6dcjvzJwzkCGLhxKjfAaJP0xiU6NO2kwuJRREIhIrpJ/TCZ+Wjwb9m4g5qoYXmjxAtUrVfe7LPGAgkBETrB532Z6z+jNxJUTaVSzEV/c/wXNI5v7XZZ4SEEgIkBgMHjE4hEM+GwA6ZnpPH/L8/S5po8Gg0OAgkBEWPLzEmKTY0nZkkKr37ViZNuR1Ktez++yJEgUBCIhbP/h/Tw1+ymGfTWMmuE1GXf3ODo06qDB4BCjIBAJUR/98BEPTX+Izfs2E/v7WJ5v8TxnVjzT77LEBwoCkRCzce9GHpr+EJNWTeLSsy9l/D3juabONX6XJT5SEIiEiPTMdN5Y9Ab/mP0PMl0mL7V4iUeaPUK5sHJ+lyY+UxCIhIDFmxcTmxzL0q1LaVO/DSPajCDqzCi/y5JiooyXb25mrc1slZmtMbN+ebTpYGYrzGy5mb3vZT0ioWbf4X30nt6bpm81ZeuvW5lw7wSSOyUrBOQEnvUIzCwMGAG0BDYBi81ssnNuRbY29YEngObOud1mdrZX9YiEEuccE1dOpPeM3vy8/2fir45n8M2DqVaxmt+lSTHk5amhJsAa59xaADMbB7QDVmRr8yAwwjm3G8A5t83DekRCQuqeVHpN70Xyj8lcce4VfNjxQ5rUauJ3WVKMeRkEtYCN2Z5vAprmaHMRgJl9CYQBA51zM3K+kZnFADEAkZGRnhQrUtIdzTjK64te5+k5TwPwSstXeLjZw5Qto6FAOTm/f0LKAvWBG4HawDwzu9Q5tyd7I+dcIpAIEB0d7YJdpEhxt2jTImKTY/n2l2+546I7GN5mOJHV9EeTFIyXQbAZqJPtee2sbdltAhY5544C68zsRwLBsNjDukRKjb2H9vLkp08yKmUU51c5n4kdJtK+QXvNDJZC8fKqocVAfTO7wMzKA/cBk3O0+YhAbwAziyBwqmithzWJlArOOSYsn0CDEQ0Y/fVoejftzcr4ldzV8C6FgBSaZ0HgnEsHegEzgZXAeOfccjN7xszuzGo2E9hpZiuA2UBf59xOr2oSKRGSkiAqCsqUCXxOSjph97rd62j7fls6fNCB86ucz1d//YqhrYdSpUIVX8qVks+cK1mn3KOjo11KSorfZYh4IykJYmIgLe1/28LDITGRo/d14LWFrzFwzkDCyoQx+KbBxDeJ12CwFIiZfe2ci85tn36CRIqT/v1PDAGAtDQWDH2M2H0v8v2277mrwV0Mu20YtavW9qdGKXUUBCLFyYYNJzzdXRGeaAGJv99K7UPlmHTfJO68+M48XixyahQEIsVJZCSkpuKAcY3h0dawPRweXV6FQUkrqFy+st8VSink6b2GRKSQEhL46fyKtO4Cf7oHIvdCytiKDGk/SiEgnlGPQKSYOJJxhFciU3k2NoNyh403pjl6bIskbPBz0Lmz3+VJKaYegYjX8rkcFOCLDV9w5Zgr6f9Zf25v2I6Vj2+k1yJH2LpUhYB4Tj0CES/17AmjR8Oxy7RTUwOXhwJ07syug7u4e/TjzNn3FuyJpObiKbS/8HZqVfWvZAk9CgIRryQlnRgCx6Sl4fo/SdKljvjJfdh3dBcseAzmDGT70TOIWRpopo6ABIsmlIl4JSoq0APIYfVZ0ON2+LQelN/WlCP/HQO/XH5Cm7p1Yf364JQpoUETykT8kGNOwOEweKk5JFwPFTKNkW1G0LNZDGSG5fdSEU9psFjEK9nWzphbF66Ig6duhnY/wA8XDaPH1T2oW+e3IZDjpSKeyzcIzOwhM6sejGJESoSkJIiIALPAR0RErlcCkZDAjhqVeKAd3Hg/HC4L0/8F/6nZg/O69jrWhPDwE18WHh7YLhIsBekRnENgveHxWYvR6x63ErqSkuCBB2Bntpvk7twJ999/Qhg45/hno3QujA/j/y6Dxz+HmaPrULnlv2DkyOPtOneGxMTAmIBZ4HNiogaKJbgKNFic9cv/VuB+IBoYD7ztnPvJ2/J+S4PF4qs8BoCB4yO8q3asIm5qHHPWz6HMpmvJnDwatl0KHL+RqH7RS9CdbLC4QGMELpAWW7M+0oHqwAdm9lKRVSlSEpxkFPfQ5lQGzhlI4xGXMW/VNzBlNJlvf348BCBwY9H+/YNRqEjB5XvVkJk9DPwF2AG8RWDxmKNmVgZYDfzd2xJFipGsm8Ll9NkFENe+LKvnDiJsxZ/InPoqHDgn17fQFUFS3BSkR3AW8EfnXCvn3ISs9YVxzmUCt3tanYjfst8eIiICduw4Yff2cOjaHm7pCpkRZ3H2zJlkjE/KMwRAVwRJ8ZNvj8A59/RJ9q0s2nJEipGcq4VlGyB2wLtXQt+WsL8C9K/ejv49/s0ZAyqd9C11RZAUR5pQJpKX3FYLA1ZGQNztMC8KrttagTHPLOGSmpcAeZ45AgJjyQkJGiiW4kcTykTykuNk/sGy8I+b4PIe8P058NYkmDvm8PEQgLznBfzrX4FbRigEpDhSEIjkJdvJ/Fn14NKeMPgG6LgMfhgO3ZfCljJ1T5hLpnkBUhLp1JBIXhIS2NLrQf5+80GSLoP6O+GTf8It6wK7DxDO3zMSmPS/u0of/6xf/FKSqEcgkotMl8lf96ZxQawxvhH8Yw58OuosLltXg0yM9dTlQRL5N501N0BKPPUIRHJYvm05scmxfLn9S/jlBkgezbM7GvDsSV6juQFSkikIRLKkHU3jvlGDmbLzZThUDT5+F77pCuR/ey3NDZCSTEEgAsxcM5O//Kcn29LXwrfdYNbLkBaRa1uzExcd09wAKek0RiAhbeuvW+n03060TmrNrp1l4b3PYNK7eYZAeDjExemqICld1COQkJTpMkn8OpF+n/TjYPpBBt4wkIEt+0F6hTxfU6MGvP66fulL6aMgkJDz/S/fE5scy4JNC7gp6iZGtR3FxREX826tvGcFA1SurBCQ0kmnhiRkHDhygMdnPc6VY65k9a7VjG0/lk//8ikXR1wM5D4rODtdGSSlladBkLWi2SozW2Nm/U7S7m4zc2aW66IJIgWS/U6hUVEnrBg2bfU0Go9qzEvzX6LbFd34If4H/nz5n8m+4N6xWcFhuS8jrCuDpNTy7NSQmYUBI4CWwCYCy11Ods6tyNGuCvAwsMirWiQE5LxTaGoqxMSwJX03j4TPY8KKCTSMaMjcbnO5vu71eb7NsVM/2d8KdGWQlG5e9giaAGucc2udc0eAcUC7XNo9C7wIHPKwFintctwpNMNgRKM0Gv7Ym8mrJjP4psF8E/fNSUPgGN0vSEKNl4PFtYCN2Z5vAppmb2BmVwF1nHNTzaxvXm9kZjFADECk+ueSm2wn8L85F2LugMW1oMVPjlFDl3HhWRcW6u10vyAJJb4NFmctdfkq8Lf82jrnEp1z0c656Jo1a3pfnJQM2ccEypTh1/Lw2K0QHQOp1SDpv/DxvMhCh4BIqPGyR7AZqJPtee2sbcdUARoDc7IG7M4FJpvZnc65FA/rktIgx5jAlN9lEN8WNlaDmBR44ROokhmOvfOcz4WKFH9e9ggWA/XN7AIzKw/cB0w+ttM5t9c5F+Gci3LORQELAYWAFEzWmMCmqvDHjnDnn6DqYZjzdhlGJRt7D9XlQZdIEjq/I5Ifz3oEzrl0M+sFzATCgHecc8vN7BkgxTk3+eTvIJK3jI2pjGgK/W+GjDLw/CfQZwGUzXCEkRlodBRm99e5fpH8eDqz2Dk3DZiWY9tTebS90ctapPRY8vMSYnqW5+uII7ReDSOmQb3dgX3rOfFiAk0CE8mfZhZLibH/8H4enfEoV795NZvPqcT7H5ZnWtL/QuAA4TzJiRf76yIzkfwpCKRE+OiHj7hk5CW8vuh1Yn8fy6DI9Xy84h1SqfubFcOO0SQwkYLRTeekWNu4dyMPTX+ISasmcdk5lzHh3gk0q92MqChIPdqZ93IMBoeFQWZmoCeQkKDxAZGCUI9A/HGS+wIBpGem89qC12g4oiGz1s7ipRYvkfJgCs1qNwPyPvefmRn4WL9eISBSUOoRSPDlcV8gADp3ZvHmxcQmx7J061La1m/L8DbDiToz6oS3iIzM/ZbRGhMQKTz1CCT4ctwXCIC0NPYNfILe03vT9K2mbP11Kx/c+wFTOk35TQhA7reM1piAyKlREEjw5Tiv44D/NoSGd25k+FfDib86npXxK7n7krtPuE10droxnEjR0akhCb5s53VSq0GvNpB8MVyxsxwf/vULmtRqUqC30Y3hRIqGegQSfAkJHK1ciVeuhUviYfYFMOSzcixu8laBQ0BEio56BBI0SUmB4YHUjN9Ro1tNdkZs4I5VMPzbWkQ++aL+vBfxiYJAgiIpCR7stZeD1z4JV49i5/7zKf/hRDo81p7I93MfBxCR4NCpIfGcc45H3hzPwe4NIHo0LOoNw1dy5Nu7GDBAISDiN/UIxFPrdq+j57Se7LhpBmy5Cv49BbZEH9+vm8KJ+E9BIJ44mnGUVxe8yqC5gwgrE0b1RUPZPTMeMk/8kdMEMBH/KQikyM3fOJ/Y5FiWbVvGXQ3uYthtw5gbWZuYuSfOI9MEMJHiQWMEUmR2H9xNXHIczd9pzt5De/mo40dM7DiR2lVrawKYSDGmHoGcNucc45aN45GZj7AjbQd9mvVh0E2DqFy+8gntNAFMpHhSEMhp+WnXT/SY2oNZa2dx9flXM6PzDK4870q/yxKRQlAQyCk5knGEV+a/wrPznqVcmXK8cdsb9IjuQViZML9LE5FCUhBIoX2e+jlxU+NYsX0F91xyD0NbDaVW1Vp+lyUip0hBIAW26+AuHp/1OG8tfYu61eoypdMUbr/odr/LEpHTpCCQfDnnSPo+iT4z+7Dr4C76XtuXp294mjPKn+F3aSJSBBQEclKrd66mx9QefLruU5rWasqsP8/i8nMv97ssESlCCgLJ1eH0w7z05UskfJ5AxbIVGdV2FDG/j6GMaeqJSGmjIJD/3R96wwaIjGTugC7EHf4vP+z4gY6NOvJaq9c4r8p5flcpIh5REIS6bAvJ76wEfa9I5d3NCVxQtibTO0+n9YWt/a5QRDymIAh1/fvj0tIYezk8divsqQhPfA4D1lUkvL9CQCQUKAhC3KoDqcR1hTkXwLUbYEwyNN4G2Ca/SxORIFEQhKhD6Yd44YsXeL4HhB+BxMnQfSmUcVkNdH9okZChIAhBs9fNJm5qHD/u/JF6K69l1vSl1Dtw8Pj+9PLhlNX9oUVChqfXAppZazNbZWZrzKxfLvv7mNkKM/vOzD41s7pe1hPqth/YTtePunLz2JvJyMzg7JkzWfvBlww48CbrqUsmxnrq0qeK7g8tEkrMOZd/q1N5Y7Mw4EegJbAJWAx0cs6tyNbmJmCRcy7NzHoANzrnOp7sfaOjo11KSoonNZc6WZeFug2pvHdzDR674TD7OUzfa/sy4PoBnFGhErl9+80gMzP45YqId8zsa+dcdG77vOwRNAHWOOfWOueOAOOAdtkbOOdmO+eOrVm1EKjtYT2hJeuy0JUHUrmxKzzwh51ckprGN7UHk3BLApXKVcpzGEDDAyKhxcsgqAVszPZ8U9a2vHQHpue2w8xizCzFzFK2b99ehCWWTklJsLr7E/yjaRqX94Dvz4G3JsHcdzK5ZNDI4+0SEgLLRWan5SNFQk+xGCw2sy5ANHBDbvudc4lAIgRODQWxtBInKQm6J3xCnZiNrKkBf/4WXvkYzj6Q1WDDhuNtjw0DZJtUTEKChgdEQo2XQbAZqJPtee2sbScwsxZAf+AG59xhD+sp9bYd2EbszD4c7phE+s6yfPLPdG5Zl6NRjvM+Wj5SRLw8NbQYqG9mF5hZeeA+YHL2BmZ2JTAGuNM5t83DWkq1TJfJW0veosHwBhyIGg9znqLJqESardN5HxHJn2c9Audcupn1AmYCYcA7zrnlZvYMkOKcmwy8DFQGJpgZwAbn3J1e1VQaLd+2nNjkWL7c+CU31L2B1a+NZst3DRgPhFGe5+hPJBvYEhZJ7USd9xGR3/Ls8lGv6PLRgINHD/LsvGd5ef7LVKtQjVdufYWul3fl/fft2D3kjgsPh0RNDRAJaSe7fLRYDBZL4cxcM5Oe03qydvdaul3RjZdbvkxEeASgAWARKTwFQQmy9detPDrzUcYtG8fFNS5mdtfZ3Bh142/aaQBYRApDQVACZLpMEr9OpN8n/TiYfpBBNw7i8eaPU6FsBb9LE5FSQEFQzH3/y/fEJseyYNMCbr7gZka1HcVFNS7yuywRKUUUBMXUgSMHeGbuMwxZMITqlaoztv1YulzWhayrq0REioyCoBiatnoa8dPiWb9nPd2v7M6LLV6kRngNv8sSkVJKQVCMbNm/hUdmPMKEFRNoGNGQud3mcn3d6/0uS0RKOQVBMZCRmcHolNE8+dmTHE4/zOCbBtO3eV/Kh5X3uzQRCQEKAp99s/UbYpNj+WrzV7So14JRbUdx4VkX+l2WiIQQBYFPfj3yKwPnDGTowqHUCK9B0h+T6NS4kwaDRSToFAQ+mLJqCr2m92LD3g08eNWDvNDiBc6qdJbfZYlIiFIQBNHmfZvpPaM3E1dOpFHNRnxx/xc0j2zud1kiEuIUBEGQkZnBiMUjGPDZAI5mHuW5m5/jb9f+TYPBIlIsKAg8tuTnJcQmx5KyJYVWv2vFyLYjqVe9nt9liYgcpyDwyP7D+3l6ztO8vuh1zj7jbMbdPY4OjTpoMFhEih0FgQcm/TCJXtN7sXnfZuKi43juluc4s+KZfpclIpIrBUER2rh3Iw9Nf4hJqyZx2TmXMeHeCTSr3czvskRETkpBUATSM9N5Y9Eb/GP2P8h0mbzc8mUebvow5cLK+V2aiEi+FASnafHmxcQmx7J061La1m/L8DbDiTozyu+yREQKTEFwivYd3seAzwYw/KvhnFv5XD649wP+2PCPGgwWkRJHQVBIzjkmrpxI7xm9+Xn/z8RfHc/gmwdTrWI1v0sTETklCoJCWL9nPb2m9WLq6qlcce4VfNjxQ5rUauJ3WSIip0VBUABHM44ydOFQBs4diGEMuXUIvZv2pmwZ/fOJSMmn32T5WLhpIbHJsXz3y3fccdEdDG8znMhqkX6XJSJSZBQEedhzaA9Pfvoko1NGc36V85nYYSLtG7TXYLCIlB0kn6gAAAbqSURBVDoKghycc0xYMYGHZzzMtgPb6N20N8/e9CxVKlTxuzQREU8oCLJZt3sdPaf1ZMaaGVx13lVM6TSF6POj/S5LRMRTCgICg8GvLniVQXMHEVYmjKGthhLfJF6DwSISEkL+N938jfOJTY5l2bZl3NXgLobdNozaVWv7XZaISNCEbBDsPribJz59gjFfj6FO1TpMum8Sd158p99liYgEXRkv39zMWpvZKjNbY2b9ctlfwcz+k7V/kZlFeVkPBAaD//39v2kwogFvLnmTPs36sCJ+hUJAREKWZz0CMwsDRgAtgU3AYjOb7Jxbka1Zd2C3c+5CM7sPeBHo6FVNP+36iZ7TevLxTx9z9flXM6PzDK4870qvvpyISIngZY+gCbDGObfWOXcEGAe0y9GmHfDPrMcfALeYRxfqv7v0XRqPasyCjQt447Y3WNB9gUJARARvxwhqARuzPd8ENM2rjXMu3cz2AjWAHdkbmVkMEAMQGXlqs3rr16jP7RfdztBWQ6lVtdYpvYeISGlUIgaLnXOJQCJAdHS0O5X3uC7yOq6LvK5I6xIRKQ28PDW0GaiT7XntrG25tjGzskA1YKeHNYmISA5eBsFioL6ZXWBm5YH7gMk52kwGumY9vgf4zDl3Sn/xi4jIqfHs1FDWOf9ewEwgDHjHObfczJ4BUpxzk4G3gf8zszXALgJhISIiQeTpGIFzbhowLce2p7I9PgTc62UNIiJycp5OKBMRkeJPQSAiEuIUBCIiIU5BICIS4qykXa1pZtuB1FN8eQQ5Zi2HgFA7Zh1v6Rdqx1xUx1vXOVcztx0lLghOh5mlOOdCasmxUDtmHW/pF2rHHIzj1akhEZEQpyAQEQlxoRYEiX4X4INQO2Ydb+kXasfs+fGG1BiBiIj8Vqj1CEREJAcFgYhIiCuVQWBmrc1slZmtMbN+ueyvYGb/ydq/yMyigl9l0SnA8fYxsxVm9p2ZfWpmdf2osyjld8zZ2t1tZs7MSvTlhgU5XjPrkPV9Xm5m7we7xqJWgJ/rSDObbWZLs3622/hRZ1Ews3fMbJuZLctjv5nZsKx/i+/M7KoiLcA5V6o+CNzy+iegHlAe+Ba4JEebnsDorMf3Af/xu26Pj/cmIDzrcY+SfLwFPeasdlWAecBCINrvuj3+HtcHlgLVs56f7XfdQTjmRKBH1uNLgPV+130ax3s9cBWwLI/9bYDpgAHNgEVF+fVLY4+gCbDGObfWOXcEGAe0y9GmHfDPrMcfALeYmQWxxqKU7/E652Y759Kyni4ksFpcSVaQ7zHAs8CLwKFgFueBghzvg8AI59xuAOfctiDXWNQKcswOqJr1uBqwJYj1FSnn3DwCa7LkpR0w1gUsBM40s/OK6uuXxiCoBWzM9nxT1rZc2zjn0oG9QI2gVFf0CnK82XUn8JdFSZbvMWd1nes456YGszCPFOR7fBFwkZl9aWYLzax10KrzRkGOeSDQxcw2EVj35KHglOaLwv4/L5QSsXi9FA0z6wJEAzf4XYuXzKwM8CrQzedSgqksgdNDNxLo8c0zs0udc3t8rcpbnYD3nHNDzOwaAqsdNnbOZfpdWElTGnsEm4E62Z7XztqWaxszK0ugW7kzKNUVvYIcL2bWAugP3OmcOxyk2ryS3zFXARoDc8xsPYFzqpNL8IBxQb7Hm4DJzrmjzrl1wI8EgqGkKsgxdwfGAzjnFgAVCdygrTQq0P/zU1Uag2AxUN/MLjCz8gQGgyfnaDMZ6Jr1+B7gM5c1IlMC5Xu8ZnYlMIZACJT0c8eQzzE75/Y65yKcc1HOuSgC4yJ3OudS/Cn3tBXkZ/ojAr0BzCyCwKmitcEssogV5Jg3ALcAmFlDAkGwPahVBs9k4C9ZVw81A/Y6534uqjcvdaeGnHPpZtYLmEngyoN3nHPLzewZIMU5Nxl4m0A3cg2BAZr7/Kv49BTweF8GKgMTssbENzjn7vSt6NNUwGMuNQp4vDOBW81sBZAB9HXOldRebkGP+W/Am2b2KIGB424l9Q86M/s3gSCPyBrzeBooB+CcG01gDKQNsAZIA+4v0q9fQv/dRESkiJTGU0MiIlIICgIRkRCnIBARCXEKAhGREKcgEBEJcQoCEZEQpyAQEQlxCgKR02RmV2fdI76imZ2RtR5AY7/rEikoTSgTKQJmNpjALQ4qAZucc8/7XJJIgSkIRIpA1v1wFhNY++Ba51yGzyWJFJhODYkUjRoE7udUhUDPQKTEUI9ApAiY2WQCq2hdAJznnOvlc0kiBVbq7j4qEmxm9hfgqHPufTMLA+ab2c3Ouc/8rk2kINQjEBEJcRojEBEJcQoCEZEQpyAQEQlxCgIRkRCnIBARCXEKAhGREKcgEBEJcf8PWZsT+U9VxO4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = fit_stoch(X_norm, y)\n",
    "X_matrix = np.array(X_norm)\n",
    "for i in range(len(y)):\n",
    "    if y[i] > 0:\n",
    "        plt.scatter(X_matrix[i,1], X_matrix[i,2], color='red')\n",
    "    else:\n",
    "        plt.scatter(X_matrix[i,1], X_matrix[i,2], color='blue')\n",
    "lin = np.linspace(0, 1,\n",
    "               num = len(X_norm),\n",
    "               endpoint = True)\n",
    "plt.plot(lin, -lin*w[1]/w[2] - w[0]/w[2] + 0.5/w[2], color='green')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 34 Weights:  [ 0.5        -0.04132955  0.04340361]\n",
      "y_fail: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.5       , -0.04132955,  0.04340361])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = fit_stoch(X_norm, y)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored weights [2656.0000000000014, -0.002861421814610233, 0.04340361445783126]\n",
      "Weights with y set to 1 [61193.060374739885, -0.06592588774813316, 1.0]\n"
     ]
    }
   ],
   "source": [
    "w = [w[i] * maxima[-1] / maxima[i] for i in range(len(w))]\n",
    "print(\"Restored weights\", w)\n",
    "w = [w[j] / w[-1] for j in range(len(w))]\n",
    "print(\"Weights with y set to 1\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x117127f10>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_fr, y_fr, color='red')\n",
    "plt.scatter(x_en, y_en, color='blue')\n",
    "plt.plot([min(x_fr + x_en), max(x_fr + x_en)],\n",
    "             [-w[1] * min(x_fr + x_en) - w[0], -w[1] * max(x_fr + x_en) - w[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Evaluate your perceptron using the leave-one-out cross validation method. You will have to train and run 30 models. In each train/run session, you will train on 29 samples and evaluate on the remaining sample. You have then either a correct or a wrong classification. You will sum these classifications, i.e. the number of correct classifications, to get your final evaluation, for instance 29/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n",
    "def leave_one_out_cross_val(X, y, fitting_function):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "#X_test = []\n",
    "#y_test = []\n",
    "    b = 0\n",
    "    evaluate = 0\n",
    "\n",
    "    num = int(np.array(X).shape[0])\n",
    "\n",
    "    for i,x in enumerate(X_norm):\n",
    "        for nbr in X_norm:\n",
    "            if nbr == x:\n",
    "                X_test = [nbr]\n",
    "                y_test = [y[i]]\n",
    "                continue\n",
    "            X_train.append(nbr)\n",
    "            y_train.append(y[i])\n",
    "        w_train = fit_stoch(X_train, y_train)\n",
    "        y_pred = predict2(X_test, w_train)\n",
    "        evaluate += accuracy(y_test, y_pred)\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "\n",
    "    print(evaluate/len(X_norm))\n",
    "    \n",
    "    return evaluate/len(X_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 0 Weights:  [0. 0. 0.]\n",
      "y_fail: 0.0\n",
      "Epochs: 2 Weights:  [0.42       0.19255718 0.18477598]\n",
      "y_fail: 2.0\n",
      "Epochs: 2 Weights:  [0.43       0.19888954 0.19011107]\n",
      "y_fail: 4.0\n",
      "Epochs: 2 Weights:  [0.41       0.19830903 0.18973833]\n",
      "y_fail: 2.0\n",
      "Epochs: 2 Weights:  [0.43       0.19633066 0.18749435]\n",
      "y_fail: 3.0\n",
      "Epochs: 2 Weights:  [0.42       0.18919166 0.1804744 ]\n",
      "y_fail: 2.0\n",
      "Epochs: 2 Weights:  [0.42       0.19011352 0.18160956]\n",
      "y_fail: 3.0\n",
      "Epochs: 2 Weights:  [0.43       0.18710681 0.17926581]\n",
      "y_fail: 4.0\n",
      "Epochs: 2 Weights:  [0.42       0.18878136 0.18006965]\n",
      "y_fail: 3.0\n",
      "Epochs: 2 Weights:  [0.43       0.19258012 0.18448983]\n",
      "y_fail: 4.0\n",
      "Epochs: 2 Weights:  [0.42       0.19343891 0.18570407]\n",
      "y_fail: 3.0\n",
      "Epochs: 2 Weights:  [0.42       0.19336474 0.18497553]\n",
      "y_fail: 4.0\n",
      "Epochs: 2 Weights:  [0.43       0.19764914 0.18908697]\n",
      "y_fail: 4.0\n",
      "Epochs: 2 Weights:  [0.43       0.19028583 0.18255271]\n",
      "y_fail: 3.0\n",
      "Epochs: 2 Weights:  [0.43       0.18846282 0.17989081]\n",
      "y_fail: 3.0\n",
      "Epochs: 2 Weights:  [0.42       0.19557328 0.18732681]\n",
      "y_fail: 3.0\n",
      "0.9666666666666667\n",
      "Cross-validation accuracy (stochastic): 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "stoch_accuracy = leave_one_out_cross_val(X_norm, y, fit_stoch)\n",
    "print('Cross-validation accuracy (stochastic):', stoch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "From your perceptron program, implement logistic regression. You can either follow the description from the textbook, S. Russell and R. Norvig, _Artificial Intelligence_, 2010, pages 725--727, or the slides. You can either implement the stochastic or the batch version of the algorithm, or both versions. As stop criterion, you will use either the norm of the gradient or the norm of the difference between two consecutive weight vectors. You will also set a maximal number of epochs. Run the resulting program on your data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the logistic function, where the $x$ input is a real number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Activation function\n",
    "def activ_func(X, w):\n",
    "    expression = 1/(1 + math.exp(-np.dot(X, w)))\n",
    "    return expression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def predict3(X, w):\n",
    "    linear_func = np.dot(X, w) \n",
    "    y_predict = activ_func(linear_func)\n",
    "    return y_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def logistic(X, y,\n",
    "              epochs=1000,\n",
    "              epsilon=1.0e-5,\n",
    "              verbose=True):\n",
    "    n_samples, n_features = np.array(X).shape\n",
    "    w = np.zeros(n_features)\n",
    "    alpha = 0.01 \n",
    "    y_fail = 0\n",
    "    y_pred = np.zeros(len(y))\n",
    "    for epoch in range(epochs):\n",
    "        indices = list(range(len(X)))\n",
    "        random.shuffle(indices)\n",
    "        for idx in indices:\n",
    "            xi = X[idx]\n",
    "            y_pred[idx] = predict3(xi, w)\n",
    "            gradient = alpha * (y[idx] - y_pred[idx])\n",
    "            w = w + np.dot(gradient, np.array(xi))\n",
    "            \n",
    "        y_fail= sum(abs(y - y_pred))\n",
    "        if np.linalg.norm(gradient) < epsilon:\n",
    "            break\n",
    "        \n",
    "    print(\"Epochs:\", epoch, 'Weights: ', w)\n",
    "    print('y_fail: {}'.format(y_fail))\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `predict(X, w)` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `predict_proba()` function that given a matrix of observations $\\mathbf{X}$ and a weight vector $\\mathbf{w}$ will return a vector of probabilities to belong to class 1: The vector will consist of $P(1|\\mathbf{x}_i)$ for all the $i$ rows of $\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def predict_proba(X, w):\n",
    "    pred = []\n",
    "    for i,x in enumerate(X):\n",
    "        expression = 1/(1 + math.exp(-np.matmul(x,w)))\n",
    "        pred.append(expression)\n",
    "    return np.array(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `predict(X, w)` function that given a matrix of observations $\\mathbf{X}$ and a weight vector $\\mathbf{w}$ will return the class. You will use `predict_proba()` and set the threshold to belong to class 1 to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#act function\n",
    "def act(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "a = np.vectorize(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def predict3(X, w):\n",
    "    return a(np.matmul(X, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `fit(X, y)` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now write the `fit(X, y)` function as with the perceptron. You may call it `fit_stoch(X, y)` or `fit_batch(X, y)`. Use the parameters given in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import random\n",
    "def fit_stoch(X, y, alpha=0.1,\n",
    "              epochs=8000,\n",
    "              epsilon=1.0e-5,\n",
    "              verbose=False):\n",
    "    max_misclassified = 5\n",
    "    samples, features = np.array(X).shape\n",
    "    w = np.zeros(features)\n",
    "    y_fail = 0\n",
    "    y_pred = np.zeros(len(y))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    random.seed(0)\n",
    "    indices = list(range(len(X)))\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(indices)\n",
    "        y_pred = predict3(X[indices,:], w)\n",
    "        gradient = np.dot(np.array(y_pred - y[indices]).T, X[indices,:])\n",
    "        w = w - alpha*gradient.T\n",
    "            \n",
    "        y_fail= sum(abs(y[indices] - np.round(y_pred)))\n",
    "        if np.linalg.norm(gradient) < epsilon:\n",
    "            break\n",
    "        \n",
    "    print(\"Epochs:\", epoch, 'Weights: ', w)\n",
    "    print('y_fail: {}'.format(y_fail))\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7999 Weights:  [ -0.16022158 -61.81842388  64.82431189]\n",
      "y_fail: 16.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z = normalize(X)[0]\n",
    "#print(Z)\n",
    "w = fit_stoch(Z, y, verbose=True) \n",
    "X_matrix = np.array(Z) \n",
    "for i in range(len(y)):\n",
    "    if y[i] > 0:\n",
    "        plt.scatter(X_matrix[i,1], X_matrix[i,2], color='red')\n",
    "    else:\n",
    "        plt.scatter(X_matrix[i,1], X_matrix[i,2], color='blue')\n",
    "lin = np.linspace(0, max(X_matrix[:,2]),\n",
    "               num = len(X_matrix),\n",
    "               endpoint = True)\n",
    "plt.plot(lin, -lin*w[1]/w[2]-w[0]/w[2], color='green')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "[0.         0.00729945 0.031843  ]\n",
      "[-0.01513218  0.00665311  0.0561182 ]\n",
      "[-0.02796694  0.00709548  0.08143536]\n",
      "[-0.04106175  0.0077862   0.10694895]\n",
      "[-0.05439574  0.00641967  0.1305017 ]\n",
      "[-0.06621485  0.00760899  0.15660715]\n",
      "[-0.07965466  0.00712018  0.18093097]\n",
      "[-0.09214581  0.00759313  0.2063474 ]\n",
      "[-0.10520181  0.00613669  0.2299162 ]\n",
      "[-0.11691996  0.00294359  0.25178832]\n",
      "[-0.12695897  0.00534088  0.2787039 ]\n",
      "[-0.14074023  0.00685491  0.30493445]\n",
      "[-0.15484327  0.00770803  0.33075464]\n",
      "[-0.16860507  0.00763197  0.35567265]\n",
      "[-0.18156439  0.00827881  0.38114547]\n",
      "[-0.19482145  0.00838764  0.40620892]\n",
      "[-0.20778116  0.01027289  0.432924  ]\n",
      "[-0.22200338  0.00097807  0.44855754]\n",
      "[-0.22785679  0.00411322  0.47592285]\n",
      "[-0.24103159  0.00864178  0.50524186]\n",
      "[-0.25734775  0.00614605  0.5273332 ]\n",
      "[-0.26890505  0.01294035  0.55845556]\n",
      "[-0.28639268  0.00693709  0.57713078]\n",
      "[-0.2955533   0.01026858  0.60545199]\n",
      "[-0.30998395  0.00904337  0.62920703]\n",
      "[-0.32220199  0.0117333   0.65668456]\n",
      "[-0.33682469  0.01223718  0.68167011]\n",
      "[-0.35024272  0.01597121  0.71015155]\n",
      "[-0.36595783  0.02092611  0.73978582]\n",
      "[-0.38317407  0.008463    0.75321143]\n",
      "[-0.38774064  0.01160719  0.78124391]\n",
      "[-0.40077959  0.00879361  0.80367151]\n",
      "[-0.4115063   0.00118127  0.82156603]\n",
      "[-4.18029104e-01  6.15044620e-04  8.45096616e-01]\n",
      "[-0.42838671 -0.00474224  0.86503424]\n",
      "[-0.43647871 -0.00183782  0.89223714]\n",
      "[-0.44998813  0.00524641  0.92404959]\n",
      "[-0.46826879  0.00144513  0.94467797]\n",
      "[-0.47928175  0.00721287  0.97453486]\n",
      "[-0.49564892  0.01248544  1.00473806]\n",
      "[-0.51333069  0.01239268  1.02914507]\n",
      "[-0.5270708   0.02642466  1.06778673]\n",
      "[-0.55064205  0.01136802  1.0781139 ]\n",
      "[-0.55479826  0.01284386  1.10298601]\n",
      "[-0.56578777  0.02750455  1.14145079]\n",
      "[-0.58877857  0.02963488  1.16850233]\n",
      "[-0.60576915  0.03368499  1.1969821 ]\n",
      "[-0.62245518  0.02953005  1.21757328]\n",
      "[-0.632934   0.0263459  1.239756 ]\n",
      "[-0.64273826  0.01856293  1.25691262]\n",
      "[-0.64870807  0.02929908  1.29160246]\n",
      "[-0.66734741  0.02151414  1.30786851]\n",
      "[-0.67534912  0.01551479  1.32648444]\n",
      "[-0.68207423  0.01019313  1.34624096]\n",
      "[-0.68914262  0.0127291   1.37496464]\n",
      "[-0.70265492  0.02115348  1.40776175]\n",
      "[-0.72165465  0.01544298  1.42832305]\n",
      "[-0.73217257  0.00827694  1.44531801]\n",
      "[-0.73852798  0.00790782  1.46979351]\n",
      "[-0.74912924  0.03177397  1.51771509]\n",
      "[-0.77875386  0.02862938  1.54075145]\n",
      "[-0.79408812  0.03979274  1.57674415]\n",
      "[-0.81571558  0.06016077  1.62318785]\n",
      "[-0.84633629  0.06158635  1.65020646]\n",
      "[-0.86518554  0.06661484  1.67971706]\n",
      "[-0.88304262  0.07096341  1.70994017]\n",
      "[-0.9006184   0.06078883  1.72257529]\n",
      "[-0.90627085  0.08878562  1.77386757]\n",
      "[-0.93690031  0.08105961  1.79267416]\n",
      "[-0.94942434  0.05677492  1.79619829]\n",
      "[-0.9451021   0.07443282  1.83841087]\n",
      "[-0.9656978   0.06314738  1.85271072]\n",
      "[-0.97245766  0.06168523  1.87653167]\n",
      "[-0.98238271  0.0345411   1.87436757]\n",
      "[-0.97425676  0.06960029  1.93081726]\n",
      "[-1.00524493  0.07035162  1.95862273]\n",
      "[-1.02433233  0.07230967  1.98483541]\n",
      "[-1.0398887   0.07046074  2.00668632]\n",
      "[-1.05146732  0.06055368  2.0217068 ]\n",
      "[-1.05648672  0.04554299  2.03097163]\n",
      "[-1.05566817  0.06370908  2.06961441]\n",
      "[-1.07585284  0.06398109  2.09370371]\n",
      "[-1.09035518  0.08130298  2.1342429 ]\n",
      "[-1.11524633  0.06786616  2.14683854]\n",
      "[-1.12207495  0.08683368  2.18919931]\n",
      "[-1.14589696  0.07179296  2.20024456]\n",
      "[-1.15133449  0.06514154  2.22023737]\n",
      "[-1.15752376  0.0658447   2.24532656]\n",
      "[-1.16839918  0.06683116  2.2690587 ]\n",
      "[-1.18028726  0.03349444  2.26240461]\n",
      "[-1.16934047  0.04284471  2.29361053]\n",
      "[-1.18040591  0.03647482  2.31214076]\n",
      "[-1.18785938  0.05236761  2.35295332]\n",
      "[-1.21004439  0.0348329   2.36053834]\n",
      "[-1.21300842  0.07744635  2.42777746]\n",
      "[-1.25247531  0.02186624  2.39842063]\n",
      "[-1.23427908  0.00858469  2.41099378]\n",
      "[-1.2283366   0.00516747  2.43411677]\n",
      "[-1.23332744  0.01390964  2.46501678]\n",
      "[-1.24867608  0.01492666  2.48988229]\n",
      "[-1.26228408  0.00435601  2.50242021]\n",
      "[-1.2669556   0.00408189  2.52853439]\n",
      "[-1.27727497  0.02646673  2.57760235]\n",
      "[-1.30524086  0.02427729  2.60360965]\n",
      "[-1.3219733   0.02188644  2.62594368]\n",
      "[-1.33392141  0.01310453  2.64590286]\n",
      "[-1.34131137  0.00576096  2.66210665]\n",
      "[-1.34651964  0.03848948  2.71972844]\n",
      "[-1.37921186  0.0165722   2.72582474]\n",
      "[-1.3838288   0.0374005   2.77160626]\n",
      "[-1.40803873  0.03673781  2.79715104]\n",
      "[-1.42405392  0.03519801  2.82112223]\n",
      "[-1.43664434 -0.0261487   2.78861019]\n",
      "[-1.40809646 -0.02430073  2.81540512]\n",
      "[-1.40879735 -0.00753135  2.85700741]\n",
      "[-1.42888108 -0.03375034  2.85899683]\n",
      "[-1.42675065 -0.02151283  2.89553184]\n",
      "[-1.44261201 -0.04206211  2.89966788]\n",
      "[-1.44187562e+00  9.19792572e-04  2.96676945e+00]\n",
      "[-1.47893436  0.00439643  2.9953835 ]\n",
      "[-1.50157477 -0.02947126  2.98914083]\n",
      "[-1.49510452 -0.0130864   3.03023516]\n",
      "[-1.51231205  0.00969132  3.07685695]\n",
      "[-1.54108625  0.03186016  3.12401666]\n",
      "[-1.57351369  0.04021189  3.15502116]\n",
      "[-1.59717085  0.09271931  3.23079799]\n",
      "[-1.6471917   0.05986291  3.22104893]\n",
      "[-1.6498374   0.07759565  3.26174927]\n",
      "[-1.66981905  0.08704649  3.29644537]\n",
      "[-1.69087134  0.11706794  3.35371294]\n",
      "[-1.72625859  0.09186268  3.35610935]\n",
      "[-1.73079012  0.08966959  3.38303327]\n",
      "[-1.74019283  0.08574462  3.40428284]\n",
      "[-1.74887974  0.08538297  3.42527877]\n",
      "[-1.75841698  0.11108086  3.47197755]\n",
      "[-1.78491869  0.07459151  3.46560669]\n",
      "[-1.78009831  0.04634435  3.46254996]\n",
      "[-1.7681069   0.08020125  3.51724292]\n",
      "[-1.79239202  0.05304614  3.51571723]\n",
      "[-1.7914402   0.10141976  3.58581504]\n",
      "[-1.82889024  0.0477277   3.55635712]\n",
      "[-1.81524914  0.05309751  3.58181082]\n",
      "[-1.82024783  0.04236027  3.59567384]\n",
      "[-1.82283585  0.06813459  3.6431554 ]\n",
      "[-1.84697717  0.09125803  3.68915476]\n",
      "[-1.87724509  0.04543602  3.6658477 ]\n",
      "[-1.8658944   0.07995272  3.72373933]\n",
      "[-1.89100937  0.09003662  3.75412441]\n",
      "[-1.91257398  0.09301007  3.78123262]\n",
      "[-1.92958886  0.08672349  3.79896546]\n",
      "[-1.93914108  0.07695528  3.81692749]\n",
      "[-1.94497019  0.06917967  3.83210942]\n",
      "[-1.94924365  0.05889852  3.84405245]\n",
      "[-1.95116192  0.11041598  3.91965662]\n",
      "[-1.9912      0.14790402  3.98292066]\n",
      "[-2.03661105  0.12367888  3.9823377 ]\n",
      "[-2.04560773  0.10694687  3.98820071]\n",
      "[-2.04543803  0.10949679  4.01644259]\n",
      "[-2.05467863  0.09256476  4.02566147]\n",
      "[-2.05555959  0.11752995  4.07689025]\n",
      "[-2.07903174  0.10260257  4.08950864]\n",
      "[-2.08688814  0.09401183  4.10765097]\n",
      "[-2.09256066  0.09568457  4.13185834]\n",
      "[-2.10241881  0.09761282  4.15830481]\n",
      "[-2.11457245  0.10545737  4.19035424]\n",
      "[-2.13106012  0.06799343  4.17869523]\n",
      "[-2.12219587  0.06077378  4.19278625]\n",
      "[-2.12082253  0.05546163  4.21116456]\n",
      "[-2.12412503  0.09049856  4.26997356]\n",
      "[-2.15353393  0.08232886  4.28873897]\n",
      "[-2.1676774   0.03886403  4.27177303]\n",
      "[-2.15464172  0.0904483   4.34435745]\n",
      "[-2.18686799  0.1324605   4.4070985 ]\n",
      "[-2.23011221  0.10098674  4.4036736 ]\n",
      "[-2.23623079  0.12638063  4.45087449]\n",
      "[-2.25993705  0.13827893  4.48729749]\n",
      "[-2.28318122  0.13360158  4.50843407]\n",
      "[-2.29689341  0.14073752  4.54006033]\n",
      "[-2.31344653  0.12956821  4.55333371]\n",
      "[-2.32038742  0.10403166  4.55117157]\n",
      "[-2.3148411   0.12396164  4.59402623]\n",
      "[-2.33089972  0.13704672  4.63091273]\n",
      "[-2.35159731  0.19788551  4.7161463 ]\n",
      "[-2.40168528  0.18686582  4.72999562]\n",
      "[-2.42229609  0.22650962  4.79498415]\n",
      "[-2.46022483  0.25261595  4.84464041]\n",
      "[-2.49679988  0.23413871  4.85310398]\n",
      "[-2.50863715  0.28062355  4.92453496]\n",
      "[-2.5464571   0.26496343  4.93318512]\n",
      "[-2.55982196  0.28708957  4.98008603]\n",
      "[-2.58444608  0.24879092  4.96997302]\n",
      "[-2.58089478  0.27358583  5.01478695]\n",
      "[-2.59874719  0.31077371  5.07463065]\n",
      "[-2.63286699  0.32667204  5.11116831]\n",
      "[-2.66136048  0.33014404  5.1373757 ]\n",
      "[-2.68127508  0.3072462   5.14196314]\n",
      "[-2.68443043  0.30182655  5.16001688]\n",
      "[-2.68909267  0.2845791   5.17030993]\n",
      "[-2.68898162  0.30635331  5.2176198 ]\n",
      "[-2.70772131  0.23158751  5.17212031]\n",
      "[-2.68238208  0.24757447  5.21083925]\n",
      "[-2.68669741  0.28925656  5.27643843]\n",
      "[-2.71770725  0.24225866  5.25794362]\n",
      "[-2.71271926  0.23129626  5.27088862]\n",
      "[-2.71102617  0.21125187  5.27139868]\n",
      "[-2.70484013  0.19718454  5.28401725]\n",
      "[-2.70168876  0.27348093  5.38059519]\n",
      "[-2.7473084   0.30631452  5.43619882]\n",
      "[-2.79032173  0.25215654  5.40988021]\n",
      "[-2.78679949  0.25405145  5.44180416]\n",
      "[-2.79427096  0.25400305  5.46815444]\n",
      "[-2.80440642  0.29207943  5.52996272]\n",
      "[-2.8353995   0.29202584  5.55545369]\n",
      "[-2.85536271  0.27329495  5.55799208]\n",
      "[-2.85952518  0.30872738  5.61794707]\n",
      "[-2.88657868  0.33418953  5.66648419]\n",
      "[-2.91773881  0.33944614  5.69439804]\n",
      "[-2.93991187  0.30477356  5.6816457 ]\n",
      "[-2.93696024  0.29025361  5.69019279]\n",
      "[-2.93396719  0.28402036  5.71399927]\n",
      "[-2.93714235  0.28611861  5.7441701 ]\n",
      "[-2.94688918  0.29659768  5.77662585]\n",
      "[-2.96232578  0.27036554  5.77405582]\n",
      "[-2.96138734  0.31863517  5.84455356]\n",
      "[-2.99197873  0.31425634  5.86071698]\n",
      "[-3.00839708  0.32202971  5.89281802]\n",
      "[-3.02589407  0.35315479  5.94922168]\n",
      "[-3.0561896   0.35171663  5.97075406]\n",
      "[-3.07470624  0.34923762  5.99577458]\n",
      "[-3.08862177  0.36292983  6.03221162]\n",
      "[-3.10761493  0.32300513  6.01579746]\n",
      "[-3.10147728  0.35937001  6.07536631]\n",
      "[-3.12327958  0.28804867  6.03393464]\n",
      "[-3.10387539  0.36417969  6.12706086]\n",
      "[-3.13856115  0.35337664  6.14148561]\n",
      "[-3.15492233  0.35369062  6.16771729]\n",
      "[-3.1689265   0.31501937  6.15837026]\n",
      "[-3.16282925  0.30409792  6.17266985]\n",
      "[-3.16081085  0.31414857  6.20779864]\n",
      "[-3.17130653  0.33225263  6.25304754]\n",
      "[-3.19202209  0.3421767   6.28241069]\n",
      "[-3.21125533  0.31193988  6.27889564]\n",
      "[-3.21128086  0.28755802  6.2757404 ]\n",
      "[-3.20418603  0.2562279   6.2687047 ]\n",
      "[-3.19107134  0.24011385  6.28149435]\n",
      "[-3.18413038  0.25674778  6.32442535]\n",
      "[-3.19601428  0.33334295  6.42781325]\n",
      "[-3.24670847  0.28654147  6.40225052]\n",
      "[-3.25144432  0.31578339  6.46020181]\n",
      "[-3.27540116  0.27607252  6.44975607]\n",
      "[-3.27359544  0.27385497  6.47152499]\n",
      "[-3.27756625  0.22949092  6.45286083]\n",
      "[-3.26337271  0.20478418  6.45556192]\n",
      "[-3.25117832  0.22471005  6.49702242]\n",
      "[-3.2609883   0.26202948  6.55875146]\n",
      "[-3.29021427  0.21849346  6.54167469]\n",
      "[-3.28825996  0.24656323  6.59290178]\n",
      "[-3.30712377  0.2215877   6.58908616]\n",
      "[-3.30847119  0.24111145  6.62994816]\n",
      "[-3.32408281  0.28961333  6.702297  ]\n",
      "[-3.3612035   0.23062877  6.66533582]\n",
      "[-3.35438645  0.20973477  6.67180925]\n",
      "[-3.34749966  0.22605852  6.71005227]\n",
      "[-3.35779633  0.23367036  6.74206801]\n",
      "[-3.37227616  0.22600942  6.75912122]\n",
      "[-3.38118507  0.24018693  6.80103391]\n",
      "[-3.39906235  0.23445918  6.82425133]\n",
      "[-3.41153941  0.27206412  6.88791896]\n",
      "[-3.44214879  0.30530558  6.94967231]\n",
      "[-3.47954302  0.27141952  6.93835374]\n",
      "[-3.48588312  0.33105094  7.02022905]\n",
      "[-3.52326267  0.3604805   7.0750651 ]\n",
      "[-3.56115118  0.29737752  7.04035635]\n",
      "[-3.55519502  0.28674225  7.05768409]\n",
      "[-3.55386444  0.28813044  7.08271971]\n",
      "[-3.5595355   0.20744949  7.02554758]\n",
      "[-3.52854997  0.24090928  7.08195824]\n",
      "[-3.53568858  0.2108033   7.07365348]\n",
      "[-3.5295977   0.27690548  7.15961681]\n",
      "[-3.56355552  0.2626264   7.17359457]\n",
      "[-3.57939422  0.22197707  7.15750582]\n",
      "[-3.57304217  0.21177998  7.17524417]\n",
      "[-3.57172065  0.19768752  7.18805701]\n",
      "[-3.57065272  0.24739184  7.25893094]\n",
      "[-3.59919619  0.23847688  7.27349835]\n",
      "[-3.6139919  0.2906146  7.3468273]\n",
      "[-3.65106681  0.30106159  7.38390097]\n",
      "[-3.67998719  0.30831286  7.4085716 ]\n",
      "[-3.70136447  0.32809341  7.45441096]\n",
      "[-3.72712275  0.32046825  7.47267873]\n",
      "[-3.74191893  0.27942439  7.4580448 ]\n",
      "[-3.73568964  0.27015526  7.47531602]\n",
      "[-3.73446109  0.24366782  7.47261466]\n",
      "[-3.72680472  0.2778653   7.53179127]\n",
      "[-3.74520294  0.28209753  7.56010483]\n",
      "[-3.76167927  0.23646545  7.54152688]\n",
      "[-3.75427674  0.26642656  7.59470963]\n",
      "[-3.77030762  0.26147465  7.61884741]\n",
      "[-3.7824612   0.33613927  7.71754547]\n",
      "[-3.82908929  0.37671293  7.78007057]\n",
      "[-3.87575986  0.43774886  7.8609785 ]\n",
      "[-3.93147827  0.45308617  7.90143706]\n",
      "[-3.9715838   0.48095802  7.95405879]\n",
      "[-4.00980669  0.4776277   7.97067038]\n",
      "[-4.0316455   0.46493288  7.98601646]\n",
      "[-4.04294123  0.46052679  7.99970141]\n",
      "[-4.05059944  0.5085228   8.06748777]\n",
      "[-4.0809289   0.53995523  8.12350367]\n",
      "[-4.11591428  0.55551538  8.158624  ]\n",
      "[-4.14482925  0.50752642  8.13816194]\n",
      "[-4.14353078  0.55167387  8.20551992]\n",
      "[-4.16820904  0.55361847  8.23291557]\n",
      "[-4.18712824  0.56753603  8.27712122]\n",
      "[-4.20968591  0.58292196  8.31628564]\n",
      "[-4.23327861  0.62774093  8.39133792]\n",
      "[-4.27210418  0.67904691  8.46449322]\n",
      "[-4.31959155  0.58500815  8.40202321]\n",
      "[-4.30830956  0.59219278  8.43305937]\n",
      "[-4.31107651  0.59057652  8.45678724]\n",
      "[-4.3173431   0.58819979  8.47711697]\n",
      "[-4.32445995  0.62900534  8.54134685]\n",
      "[-4.35154584  0.59764032  8.53354998]\n",
      "[-4.35642854  0.65389618  8.61216082]\n",
      "[-4.38899898  0.59261042  8.58131606]\n",
      "[-4.38486738  0.63951073  8.65117974]\n",
      "[-4.40874465  0.63091623  8.66946906]\n",
      "[-4.42297667  0.7131466   8.7732392 ]\n",
      "[-4.47151152  0.68925541  8.77698927]\n",
      "[-4.49177753  0.72311138  8.83587136]\n",
      "[-4.52260452  0.70303743  8.84232746]\n",
      "[-4.53534129  0.69817701  8.86345811]\n",
      "[-4.5453898   0.72505043  8.91044812]\n",
      "[-4.56678066  0.72118872  8.93422893]\n",
      "[-4.58209569  0.74456987  8.98007984]\n",
      "[-4.60514495  0.77015162  9.02699749]\n",
      "[-4.63289654  0.67918899  8.96102691]\n",
      "[-4.61275629  0.63308582  8.93833024]\n",
      "[-4.5870487   0.64406703  8.97311675]\n",
      "[-4.58366747  0.59408558  8.94670849]\n",
      "[-4.56498469  0.65292653  9.02197602]\n",
      "[-4.58477985  0.67618265  9.06745911]\n",
      "[-4.61003102  0.70727895  9.12384481]\n",
      "[-4.64218256  0.70436873  9.14201156]\n",
      "[-4.66211408  0.67615106  9.13711333]\n",
      "[-4.66513657  0.7112563   9.19358708]\n",
      "[-4.6866369   0.69887785  9.20414161]\n",
      "[-4.69734004  0.74173359  9.27152464]\n",
      "[-4.72684507  0.79391228  9.34297156]\n",
      "[-4.76902084  0.79032975  9.36154985]\n",
      "[-4.79423743  0.73046396  9.32689251]\n",
      "[-4.78687443  0.74060809  9.35633021]\n",
      "[-4.79150496  0.72154145  9.36115006]\n",
      "[-4.79074772  0.73717225  9.39535698]\n",
      "[-4.8010712   0.7448674   9.43251861]\n",
      "[-4.81607965  0.82003086  9.52682939]\n",
      "[-4.8604787   0.81874854  9.55168212]\n",
      "[-4.88880483  0.75669276  9.51629885]\n",
      "[-4.8826675   0.83500087  9.6108417 ]\n",
      "[-4.91653726  0.8821321   9.682121  ]\n",
      "[-4.95971159  0.91401263  9.73789586]\n",
      "[-5.00120509  0.84725707  9.70192202]\n",
      "[-5.00117731  0.86741047  9.74342649]\n",
      "[-5.01424126  0.84912574  9.75095777]\n",
      "[-5.01879423  0.85931336  9.784063  ]\n",
      "[-5.03035948  0.93743785  9.88470777]\n",
      "[-5.07447153  0.96883111  9.93690565]\n",
      "[-5.11563726  1.04172021 10.03118795]\n",
      "[-5.17288468  1.02683722 10.04365692]\n",
      "[-5.20295922  1.00401175 10.04339095]\n",
      "[-5.21417656  0.93548828 10.00677525]\n",
      "[-5.19792961  1.05094129 10.13956135]\n",
      "[-5.2413801   1.10265973 10.21602365]\n",
      "[-5.29156244  1.05508109 10.19761691]\n",
      "[-5.30472941  0.98939815 10.1602258 ]\n",
      "[-5.29014415  1.03243496 10.22493658]\n",
      "[-5.30473645  1.01067895 10.22487542]\n",
      "[-5.30798056  1.06232115 10.29449354]\n",
      "[-5.33504088  1.05759492 10.31467838]\n",
      "[-5.35283676  1.07674334 10.35530907]\n",
      "[-5.37488459  1.09489793 10.39810837]\n",
      "[-5.39946512  1.08315244 10.41433075]\n",
      "[-5.4136574   1.06011032 10.4144049 ]\n",
      "[-5.41651794  1.08936508 10.46586023]\n",
      "[-5.43477153  0.99767678 10.40217629]\n",
      "[-5.41231026  1.03237728 10.4572673 ]\n",
      "[-5.41864529  0.9986466  10.44899765]\n",
      "[-5.41325857  1.0279884  10.49797248]\n",
      "[-5.4265326   1.03597323 10.53422711]\n",
      "[-5.44284875  0.95980105 10.4840981 ]\n",
      "[-5.42540598  0.88193202 10.43099289]\n",
      "[-5.38851394  0.89482757 10.46711922]\n",
      "[-5.37847888  0.91947668 10.51141292]\n",
      "[-5.3873053   0.90027221 10.51667788]\n",
      "[-5.38910659  0.96413931 10.605549  ]\n",
      "[-5.42177342  1.0123105  10.68071871]\n",
      "[-5.46504224  1.04946817 10.73977338]\n",
      "[-5.50846651  0.99277794 10.71619565]\n",
      "[-5.5154979   0.97890142 10.72552385]\n",
      "[-5.51831918  1.00444848 10.77466004]\n",
      "[-5.53520431  0.96034415 10.7550947 ]\n",
      "[-5.53121813  0.96465318 10.78444896]\n",
      "[-5.5358829   0.91295336 10.76295261]\n",
      "[-5.5232006   0.84624205 10.72413335]\n",
      "[-5.49429378  0.80816545 10.71532842]\n",
      "[-5.46858328  0.90916221 10.83528013]\n",
      "[-5.50018573  0.90353072 10.85733521]\n",
      "[-5.52075948  0.89266775 10.87366178]\n",
      "[-5.5330543   0.88548864 10.88778946]\n",
      "[-5.54114935  0.90212971 10.92272129]\n",
      "[-5.55616077  0.91800908 10.96143821]\n",
      "[-5.57556485  0.83654214 10.90336932]\n",
      "[-5.55738575  0.83613592 10.92520012]\n",
      "[-5.5517067   0.7722025  10.89342661]\n",
      "[-5.52869862  0.83743104 10.98261797]\n",
      "[-5.54783585  0.87953289 11.04555958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.57989651  0.81762779 11.012033  ]\n",
      "[-5.57775851  0.82722689 11.0470341 ]\n",
      "[-5.585664    0.83044777 11.07128268]\n",
      "[-5.59558406  0.78644337 11.0576604 ]\n",
      "[-5.58906856  0.77681029 11.07607013]\n",
      "[-5.58717229  0.87098088 11.19557134]\n",
      "[-5.62993163  0.86806284 11.21717132]\n",
      "[-5.6572155   0.84303601 11.21809808]\n",
      "[-5.66723585  0.83123494 11.23575583]\n",
      "[-5.67385695  0.77161782 11.20260774]\n",
      "[-5.65840966  0.833012   11.28339781]\n",
      "[-5.67891317  0.83134612 11.306848  ]\n",
      "[-5.69460345  0.86378306 11.36501198]\n",
      "[-5.72169056  0.86266539 11.38711698]\n",
      "[-5.74088176  0.8081054  11.36340484]\n",
      "[-5.73543852  0.84988863 11.43093467]\n",
      "[-5.75460723  0.80650866 11.4121681 ]\n",
      "[-5.75248495  0.81998395 11.44769009]\n",
      "[-5.76120431  0.79858603 11.45212066]\n",
      "[-5.76248966  0.78887072 11.46818122]\n",
      "[-5.76439481  0.80306744 11.50904407]\n",
      "[-5.77655913  0.78376903 11.50898151]\n",
      "[-5.77930529  0.79926729 11.55002456]\n",
      "[-5.7922338  0.7263228 11.5034969]\n",
      "[-5.77501823  0.77355561 11.57036643]\n",
      "[-5.78857577  0.74567278 11.56880048]\n",
      "[-5.79002463  0.75964175 11.60861193]\n",
      "[-5.80166253  0.76085491 11.63766158]\n",
      "[-5.81417777  0.70125924 11.60529394]\n",
      "[-5.8023612   0.69860239 11.62849024]\n",
      "[-5.79984655  0.62428395 11.58546927]\n",
      "[-5.77445728  0.58929562 11.57309426]\n",
      "[-5.75056776  0.74256365 11.75084862]\n",
      "[-5.80450297  0.72521257 11.75005938]\n",
      "[-5.83074693  0.75871838 11.80507036]\n",
      "[-5.86320706  0.681265   11.75137735]\n",
      "[-5.854675    0.65670364 11.75324602]\n",
      "[-5.84520305  0.71301903 11.83224133]\n",
      "[-5.86723274  0.68848212 11.82848557]\n",
      "[-5.87372633  0.68610918 11.85054132]\n",
      "[-5.8812417   0.66204298 11.85185063]\n",
      "[-5.88074101  0.6412732  11.86305119]\n",
      "[-5.87839959  0.62339303 11.87070562]\n",
      "[-5.87492057  0.76515482 12.0353528 ]\n",
      "[-5.93470578  0.70788772 12.0122734 ]\n",
      "[-5.95186412  0.70197384 12.02860474]\n",
      "[-5.96349696  0.67439416 12.02966289]\n",
      "[-5.96457555  0.64762828 12.03162363]\n",
      "[-5.96007439  0.68934643 12.09424737]\n",
      "[-5.97846373  0.70874641 12.13977186]\n",
      "[-6.00173086  0.74987227 12.20170402]\n",
      "[-6.03538956  0.66957637 12.1486627 ]\n",
      "[-6.02749781  0.70929926 12.21095857]\n",
      "[-6.04342042  0.73296608 12.259205  ]\n",
      "[-6.06669053  0.67522732 12.22507873]\n",
      "[-6.06133401  0.64979488 12.21860099]\n",
      "[-6.05184424  0.71118733 12.3030233 ]\n",
      "[-6.07558974  0.71174758 12.33099673]\n",
      "[-6.09457936  0.64183665 12.29216094]\n",
      "[-6.08344674  0.69062187 12.36871292]\n",
      "[-6.10209929  0.71059439 12.41428393]\n",
      "[-6.12561282  0.67257868 12.40075146]\n",
      "[-6.12853552  0.67502478 12.43103005]\n",
      "[-6.13660826  0.71218785 12.49093154]\n",
      "[-6.16042164  0.75039135 12.54910154]\n",
      "[-6.19298315  0.80516472 12.62672374]\n",
      "[-6.23759517  0.77213734 12.619922  ]\n",
      "[-6.25495871  0.70355014 12.57757375]\n",
      "[-6.24275532  0.69795539 12.59587769]\n",
      "[-6.23823465  0.72510684 12.65718122]\n",
      "[-6.25306266  0.68240486 12.6416406 ]\n",
      "[-6.24985818  0.64530905 12.63408676]\n",
      "[-6.23906769  0.68823796 12.70642622]\n",
      "[-6.25565538  0.64996965 12.69316013]\n",
      "[-6.25479446  0.66273948 12.73051821]\n",
      "[-6.26413681  0.5962293  12.69430583]\n",
      "[-6.24899522  0.63568385 12.75705678]\n",
      "[-6.26052677  0.69616755 12.84222459]\n",
      "[-6.2957815   0.60831468 12.78287859]\n",
      "[-6.28668516  0.6135717  12.80806846]\n",
      "[-6.28743987  0.6451101  12.85905222]\n",
      "[-6.30410117  0.67485978 12.90987603]\n",
      "[-6.32941663  0.62452347 12.88201888]\n",
      "[-6.32836695  0.71619415 12.99888817]\n",
      "[-6.36873035  0.74774155 13.05654861]\n",
      "[-6.40921316  0.78233995 13.11129369]\n",
      "[-6.44981805  0.77698621 13.13487742]\n",
      "[-6.47657631  0.79994225 13.18044751]\n",
      "[-6.50525371  0.77020395 13.183607  ]\n",
      "[-6.51644225  0.76677578 13.20495072]\n",
      "[-6.52629024  0.67855482 13.15115135]\n",
      "[-6.50408675  0.69695199 13.19883382]\n",
      "[-6.50409813  0.75175492 13.27492239]\n",
      "[-6.52957643  0.70529404 13.25617926]\n",
      "[-6.53143217  0.64425993 13.22429152]\n",
      "[-6.51424343  0.60007708 13.20856538]\n",
      "[-6.49250655  0.64743312 13.27980085]\n",
      "[-6.50308179  0.6280781  13.29374875]\n",
      "[-6.50798824  0.58602145 13.27537128]\n",
      "[-6.49891321  0.51785416 13.23558097]\n",
      "[-6.47245038  0.51884389 13.26908463]\n",
      "[-6.46384072  0.57016896 13.34410015]\n",
      "[-6.48351965  0.50212741 13.29990382]\n",
      "[-6.47279441  0.53636581 13.3542483 ]\n",
      "[-6.48387794  0.54558778 13.38729663]\n",
      "[-6.49842467  0.54688833 13.41897189]\n",
      "[-6.51312181  0.54977355 13.44931459]\n",
      "[-6.52796622  0.48056116 13.40944624]\n",
      "[-6.51512255  0.46820709 13.42475174]\n",
      "[-6.50818702  0.53100893 13.51952029]\n",
      "[-6.53480967  0.49331102 13.50346689]\n",
      "[-6.5396015   0.55622544 13.58802744]\n",
      "[-6.57098952  0.59090587 13.64393769]\n",
      "[-6.60661393  0.62060351 13.69676357]\n",
      "[-6.64310864  0.66432688 13.76499144]\n",
      "[-6.6857813   0.67256467 13.80298609]\n",
      "[-6.71934388  0.62554909 13.78404525]\n",
      "[-6.7260146   0.63968796 13.82109926]\n",
      "[-6.73968635  0.67564836 13.88695834]\n",
      "[-6.76713938  0.63613096 13.87881114]\n",
      "[-6.77383221  0.64832515 13.91599312]\n",
      "[-6.78714291  0.64183855 13.93755409]\n",
      "[-6.79769665  0.69668333 14.01730729]\n",
      "[-6.82959909  0.59298659 13.93596244]\n",
      "[-6.81259883  0.67012799 14.03109297]\n",
      "[-6.83569803  0.61897906 13.99730206]\n",
      "[-6.83282124  0.63025287 14.03962113]\n",
      "[-6.84131453  0.58095804 14.01399621]\n",
      "[-6.83180346  0.64007865 14.09400536]\n",
      "[-6.85286497  0.65935918 14.14399908]\n",
      "[-6.87832135  0.59320153 14.10000883]\n",
      "[-6.87203835  0.53688571 14.07262267]\n",
      "[-6.85219395  0.5531093  14.11298139]\n",
      "[-6.85135267  0.43555254 14.02136639]\n",
      "[-6.81057245  0.48508722 14.09328615]\n",
      "[-6.81000641  0.52073561 14.14569908]\n",
      "[-6.82652654  0.52831753 14.17316501]\n",
      "[-6.8428219   0.59862787 14.26237773]\n",
      "[-6.88279126  0.53453903 14.2204455 ]\n",
      "[-6.88582745  0.67482143 14.38483285]\n",
      "[-6.94560279  0.60424126 14.34685754]\n",
      "[-6.95990687  0.64206289 14.40114297]\n",
      "[-6.98577984  0.66349941 14.44057224]\n",
      "[-7.01248573  0.6325939  14.43098727]\n",
      "[-7.0204271   0.58638778 14.40468221]\n",
      "[-7.0112344   0.54534873 14.39270571]\n",
      "[-6.9956172   0.55284525 14.42735879]\n",
      "[-6.99435607  0.60821712 14.50680149]\n",
      "[-7.01915851  0.52745912 14.45000422]\n",
      "[-7.00751408  0.62119545 14.55992975]\n",
      "[-7.03928969  0.60518235 14.5686366 ]\n",
      "[-7.05653231  0.56858845 14.56014414]\n",
      "[-7.05804183  0.62173078 14.64455043]\n",
      "[-7.08487681  0.62043694 14.66860536]\n",
      "[-7.10492549  0.64083755 14.71478901]\n",
      "[-7.12925086  0.67281896 14.77089844]\n",
      "[-7.16015223  0.60774553 14.73464714]\n",
      "[-7.15922778  0.55483108 14.707044  ]\n",
      "[-7.14337053  0.59918456 14.77667763]\n",
      "[-7.15542617  0.65807466 14.8597455 ]\n",
      "[-7.18920689  0.61433623 14.84037384]\n",
      "[-7.19726317  0.59130142 14.84169973]\n",
      "[-7.19786134  0.56392156 14.8477525 ]\n",
      "[-7.19407441  0.49359197 14.80402497]\n",
      "[-7.1702063   0.60039297 14.92948649]\n",
      "[-7.19976307  0.66092049 15.00855145]\n",
      "[-7.24340246  0.611628   14.98589573]\n",
      "[-7.2557404   0.56411001 14.96148199]\n",
      "[-7.24947496  0.54807038 14.9710734 ]\n",
      "[-7.24444543  0.57607857 15.02903566]\n",
      "[-7.25749759  0.55675738 15.03605089]\n",
      "[-7.26285003  0.60526631 15.10995554]\n",
      "[-7.28888215  0.61235213 15.14598822]\n",
      "[-7.31233326  0.58497171 15.1459963 ]\n",
      "[-7.32108243  0.54373923 15.13040288]\n",
      "[-7.31556237  0.6075887  15.21755046]\n",
      "[-7.34042594  0.56184601 15.20353343]\n",
      "[-7.34397276  0.55933273 15.22981721]\n",
      "[-7.3504271   0.563992   15.26245499]\n",
      "[-7.36114254  0.61208172 15.33593365]\n",
      "[-7.3901025   0.53942393 15.29221412]\n",
      "[-7.38560688  0.49303972 15.27347467]\n",
      "[-7.37065508  0.41476768 15.22520479]\n",
      "[-7.33793309  0.51507993 15.34258789]\n",
      "[-7.35904354  0.5456429  15.3951456 ]\n",
      "[-7.38704726  0.56494593 15.439699  ]\n",
      "[-7.4155619   0.5863841  15.47981858]\n",
      "[-7.44398028  0.60736495 15.52261351]\n",
      "[-7.47274271  0.52500699 15.46931501]\n",
      "[-7.46469213  0.56432619 15.52977151]\n",
      "[-7.47832382  0.58536114 15.57289816]\n",
      "[-7.49830959  0.53933939 15.56161959]\n",
      "[-7.49955406  0.56539759 15.60673839]\n",
      "[-7.51342427  0.55796753 15.62826363]\n",
      "[-7.52425698  0.5150661  15.61827834]\n",
      "[-7.52084731  0.54923168 15.67666692]\n",
      "[-7.53584882  0.56912322 15.71869315]\n",
      "[-7.55622447  0.57278606 15.74576701]\n",
      "[-7.57406688  0.54870014 15.74350927]\n",
      "[-7.57986205  0.4956838  15.71608807]\n",
      "[-7.56838783  0.51189986 15.76123883]\n",
      "[-7.57272639  0.53831594 15.81035913]\n",
      "[-7.58919729  0.54809181 15.84621222]\n",
      "[-7.60743003  0.48365818 15.81457855]\n",
      "[-7.60057931  0.45656473 15.81507367]\n",
      "[-7.59144019  0.42031934 15.79551944]\n",
      "[-7.57555941  0.44093981 15.84117299]\n",
      "[-7.57815995  0.43250166 15.86238442]\n",
      "[-7.58197816  0.45271418 15.90296412]\n",
      "[-7.59541948  0.51673041 15.98230142]\n",
      "[-7.62982997  0.46429643 15.96017129]\n",
      "[-7.63676918  0.4253546  15.94520705]\n",
      "[-7.63093922  0.42120474 15.96292766]\n",
      "[-7.62984573  0.4598955  16.02654076]\n",
      "[-7.64792175  0.43216824 16.01918239]\n",
      "[-7.65230767  0.40884247 16.01905352]\n",
      "[-7.6505562   0.34246845 15.98031615]\n",
      "[-7.630028    0.34481402 16.01020415]\n",
      "[-7.62348876  0.41958628 16.10403756]\n",
      "[-7.65049006  0.40682221 16.11820952]\n",
      "[-7.666954    0.52311643 16.25162302]\n",
      "[-7.7224857   0.46941149 16.2233597 ]\n",
      "[-7.74106957  0.51120407 16.29464217]\n",
      "[-7.77286307  0.47432757 16.28659246]\n",
      "[-7.78384444  0.45537826 16.29325904]\n",
      "[-7.78817076  0.45706275 16.31962146]\n",
      "[-7.7958307  0.554325  16.4394522]\n",
      "[-7.83989479  0.57036225 16.48195053]\n",
      "[-7.87721035  0.60378914 16.53955928]\n",
      "[-7.9163201   0.55934907 16.52408563]\n",
      "[-7.92921554  0.57680158 16.56486716]\n",
      "[-7.94754463  0.56558839 16.57749129]\n",
      "[-7.95889967  0.61587625 16.64983388]\n",
      "[-7.98791235  0.62501221 16.68663972]\n",
      "[-8.01383006  0.66495898 16.75265791]\n",
      "[-8.04865943  0.753756   16.86678103]\n",
      "[-8.10623847  0.65435323 16.79733129]\n",
      "[-8.11122693  0.6680396  16.83208417]\n",
      "[-8.12291955  0.63688849 16.82804945]\n",
      "[-8.12367811  0.64544576 16.85952889]\n",
      "[-8.13125886  0.61984313 16.85793516]\n",
      "[-8.13094233  0.62735887 16.89247575]\n",
      "[-8.13820938  0.65046597 16.93762472]\n",
      "[-8.15483775  0.65385922 16.96428385]\n",
      "[-8.17035942  0.63450889 16.97772644]\n",
      "[-8.17873113  0.55255005 16.92522201]\n",
      "[-8.15963777  0.51912462 16.9183928 ]\n",
      "[-8.1405688   0.60419815 17.02912803]\n",
      "[-8.16390311  0.56725722 17.01747708]\n",
      "[-8.16946012  0.53328635 17.01192155]\n",
      "[-8.16568749  0.53021638 17.02734177]\n",
      "[-8.16552018  0.51279199 17.02885186]\n",
      "[-8.16249562  0.53617762 17.07577028]\n",
      "[-8.17315918  0.58441806 17.15672669]\n",
      "[-8.20269356  0.65306842 17.24698357]\n",
      "[-8.24907822  0.63447063 17.25659789]\n",
      "[-8.27601475  0.67519626 17.32186498]\n",
      "[-8.31137567  0.66436437 17.33918882]\n",
      "[-8.33429273  0.64493979 17.3493913 ]\n",
      "[-8.34672797  0.6286781  17.36456676]\n",
      "[-8.35411927  0.63842866 17.39378973]\n",
      "[-8.36554343  0.63102835 17.40653287]\n",
      "[-8.37349364  0.62253712 17.41849445]\n",
      "[-8.37896123  0.58901101 17.40670855]\n",
      "[-8.37422597  0.63529649 17.47647197]\n",
      "[-8.39179329  0.54250151 17.41211722]\n",
      "[-8.37468447  0.53818313 17.43190441]\n",
      "[-8.36676088  0.63316814 17.55363925]\n",
      "[-8.40014919  0.58648931 17.53489105]\n",
      "[-8.40919071  0.54762205 17.52185265]\n",
      "[-8.40550801  0.57783969 17.57549691]\n",
      "[-8.41799815  0.57328504 17.59375444]\n",
      "[-8.42808983  0.52700051 17.56693632]\n",
      "[-8.42133763  0.54234752 17.59973909]\n",
      "[-8.42561966  0.53088545 17.60470931]\n",
      "[-8.42707001  0.46192338 17.55692599]\n",
      "[-8.40719038  0.60761038 17.72100737]\n",
      "[-8.44953412  0.56555555 17.70138424]\n",
      "[-8.46491067  0.51024286 17.6690364 ]\n",
      "[-8.45889549  0.53994557 17.72482114]\n",
      "[-8.47017425  0.56335629 17.76742499]\n",
      "[-8.48875148  0.47667801 17.71171156]\n",
      "[-8.47505537  0.42353883 17.68634763]\n",
      "[-8.45254867  0.49445046 17.78649384]\n",
      "[-8.4687147   0.44526324 17.76708925]\n",
      "[-8.46654859  0.47522724 17.81759708]\n",
      "[-8.4793359   0.43930148 17.80964374]\n",
      "[-8.47944631  0.46918059 17.85999937]\n",
      "[-8.49359278  0.48985758 17.89868345]\n",
      "[-8.51277465  0.43193273 17.87453858]\n",
      "[-8.51014291  0.45620935 17.92976928]\n",
      "[-8.52240283  0.41975898 17.91795798]\n",
      "[-8.52145247  0.45363333 17.98002965]\n",
      "[-8.53764403  0.4639018  18.01715861]\n",
      "[-8.55595887  0.46891394 18.05086599]\n",
      "[-8.57406726  0.44249622 18.05064298]\n",
      "[-8.5805981   0.4678923  18.09510688]\n",
      "[-8.59685453  0.44583178 18.09561591]\n",
      "[-8.60314646  0.52905896 18.19636076]\n",
      "[-8.63916132  0.46338925 18.16432145]\n",
      "[-8.64450306  0.51558817 18.23508119]\n",
      "[-8.66925048  0.45360896 18.19993503]\n",
      "[-8.66767847  0.53302502 18.30846097]\n",
      "[-8.69936756  0.47622184 18.28123965]\n",
      "[-8.70448299  0.47456172 18.29966418]\n",
      "[-8.7105427   0.48385313 18.33404967]\n",
      "[-8.72186589  0.43895096 18.31127417]\n",
      "[-8.71708014  0.41121678 18.30832328]\n",
      "[-8.70863819  0.38747369 18.31368384]\n",
      "[-8.70004083  0.38186857 18.33328799]\n",
      "[-8.69702065  0.39725338 18.36959929]\n",
      "[-8.70408354  0.40143814 18.405917  ]\n",
      "[-8.71545758  0.34213938 18.3770806 ]\n",
      "[-8.70710028  0.35217127 18.41801479]\n",
      "[-8.71066033  0.42878547 18.52253281]\n",
      "[-8.74428205  0.38567312 18.50760096]\n",
      "[-8.75521094  0.40873099 18.54896519]\n",
      "[-8.77319464  0.43746961 18.60076041]\n",
      "[-8.79836458  0.47211406 18.65509558]\n",
      "[-8.82950001  0.51767676 18.7242469 ]\n",
      "[-8.86878435  0.48113497 18.70808041]\n",
      "[-8.88438892  0.44200019 18.69327065]\n",
      "[-8.88481091  0.36587625 18.63898083]\n",
      "[-8.86238446  0.2974763  18.59487112]\n",
      "[-8.82861946  0.29964509 18.62608376]\n",
      "[-8.81311344  0.28054835 18.62955221]\n",
      "[-8.80057669  0.3444779  18.71726324]\n",
      "[-8.81893582  0.35250057 18.75276889]\n",
      "[-8.83791867  0.41612083 18.8381385 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.8754801   0.43513876 18.87622404]\n",
      "[-8.90891788  0.40214352 18.8709546 ]\n",
      "[-8.92333806  0.40562155 18.89399696]\n",
      "[-8.93693805  0.38527856 18.90552645]\n",
      "[-8.94389507  0.34407909 18.88083122]\n",
      "[-8.93685805  0.34888277 18.91092679]\n",
      "[-8.93835963  0.38175479 18.97563595]\n",
      "[-8.95600501  0.40956376 19.02803958]\n",
      "[-8.98084076  0.37602698 19.02173789]\n",
      "[-8.98960993  0.33853737 19.01128482]\n",
      "[-8.98681161  0.28919035 18.98966229]\n",
      "[-8.97271369  0.3615148  19.08648318]\n",
      "[-8.99282962  0.37634122 19.11927539]\n",
      "[-9.01365483  0.41455352 19.18368401]\n",
      "[-9.04429863  0.38623177 19.17924868]\n",
      "[-9.05803593  0.35017597 19.1690198 ]\n",
      "[-9.05872006  0.30244934 19.14516858]\n",
      "[-9.04677987  0.28035413 19.15233602]\n",
      "[-9.0365588   0.27909321 19.18057659]\n",
      "[-9.03462997  0.30518906 19.22485787]\n",
      "[-9.04542106  0.31218438 19.25962202]\n",
      "[-9.05931268  0.38233814 19.35332939]\n",
      "[-9.09598756  0.3330569  19.33444414]\n",
      "[-9.10755089  0.40797227 19.43428526]\n",
      "[-9.14454903  0.40888327 19.46228792]\n",
      "[-9.17289598  0.41366553 19.48957239]\n",
      "[-9.19629922  0.32020888 19.42186962]\n",
      "[-9.18365572  0.41641609 19.54094499]\n",
      "[-9.21216003  0.46704155 19.61222073]\n",
      "[-9.25085702  0.48522835 19.64598716]\n",
      "[-9.28426289  0.51402965 19.70507332]\n",
      "[-9.32029895  0.51055016 19.72516603]\n",
      "[-9.34605612  0.44374257 19.68855727]\n",
      "[-9.34495878  0.51255902 19.78335123]\n",
      "[-9.37176889  0.56997559 19.86792876]\n",
      "[-9.41265315  0.59910901 19.9193303 ]\n",
      "[-9.45226342  0.52041093 19.87184632]\n",
      "[-9.4564211   0.52485752 19.9000081 ]\n",
      "[-9.46449001  0.47862848 19.88325529]\n",
      "[-9.45896844  0.46494797 19.89693245]\n",
      "[-9.45534053  0.41963199 19.88078613]\n",
      "[-9.44255744  0.49362666 19.97337579]\n",
      "[-9.46232558  0.44959537 19.95214404]\n",
      "[-9.46396994  0.45736947 19.98037734]\n",
      "[-9.47100902  0.51272565 20.05884157]\n",
      "[-9.497864    0.57688539 20.14824776]\n",
      "[-9.54062028  0.54351724 20.14457692]\n",
      "[-9.561881    0.56656937 20.19214639]\n",
      "[-9.58724705  0.49922267 20.14797506]\n",
      "[-9.58488625  0.52640892 20.19012028]\n",
      "[-9.59490515  0.5646204  20.24697263]\n",
      "[-9.61712983  0.63458119 20.34142313]\n",
      "[-9.65862628  0.56063739 20.30153977]\n",
      "[-9.66643118  0.58146816 20.34337958]\n",
      "[-9.6818129   0.61785867 20.40855443]\n",
      "[-9.70847811  0.58353233 20.40157968]\n",
      "[-9.71877873  0.59316707 20.43129399]\n",
      "[-9.7318917   0.59595233 20.46453862]\n",
      "[-9.74623535  0.58924764 20.47698772]\n",
      "[-9.75639882  0.54970784 20.45986589]\n",
      "[-9.75350051  0.58771036 20.52546212]\n",
      "[-9.76870083  0.5713739  20.5316995 ]\n",
      "[-9.77679208  0.61002948 20.59618126]\n",
      "[-9.79897738  0.62949073 20.63722691]\n",
      "[-9.82324714  0.61326702 20.64131123]\n",
      "[-9.83691695  0.59830248 20.65638692]\n",
      "[-9.84569942  0.63711851 20.71914894]\n",
      "[-9.8680353   0.63363437 20.73848972]\n",
      "[-9.88506611  0.64159958 20.76937545]\n",
      "[-9.90243183  0.75130915 20.89592559]\n",
      "[-9.9522447   0.74540728 20.91635709]\n",
      "[-9.98699571  0.76412413 20.95650049]\n",
      "[-10.01916166   0.69197779  20.90896056]\n",
      "[-10.02050343   0.73242363  20.97434956]\n",
      "[-10.03859832   0.79441319  21.06290056]\n",
      "[-10.07479208   0.77926196  21.07184217]\n",
      "[-10.09735498   0.7649406   21.08244703]\n",
      "[-10.11140859   0.65857831  21.0068334 ]\n",
      "[-10.09074652   0.64622481  21.02507208]\n",
      "[-10.07814775   0.61328067  21.02030797]\n",
      "[-10.06366645   0.62439807  21.05632978]\n",
      "[-10.06187324   0.60683405  21.06375005]\n",
      "[-10.05896497   0.61326197  21.0978259 ]\n",
      "[-10.06360356   0.59318455  21.10038418]\n",
      "[-10.0636925    0.61272391  21.14830749]\n",
      "[-10.07467396   0.59420878  21.15498155]\n",
      "[-10.079827     0.60282921  21.18266517]\n",
      "[-10.08904904   0.59883534  21.20685589]\n",
      "[-10.09826963   0.59631807  21.22789955]\n",
      "[-10.10723215   0.57224278  21.22680594]\n",
      "[-10.10890931   0.5515483   21.23653766]\n",
      "[-10.10811897   0.60345321  21.31578282]\n",
      "[-10.12885062   0.57380255  21.30822825]\n",
      "[-10.13629023   0.61960209  21.38320881]\n",
      "[-10.16065454   0.65720978  21.44403698]\n",
      "[-10.19243602   0.58290048  21.39575211]\n",
      "[-10.19332569   0.62712834  21.46540857]\n",
      "[-10.2122804    0.60069823  21.47178539]\n",
      "[-10.22135141   0.53309542  21.43054233]\n",
      "[-10.20953426   0.53779234  21.46596423]\n",
      "[-10.20822708   0.51907058  21.48152691]\n",
      "[-10.20674988   0.52748404  21.51935315]\n",
      "[-10.21319114   0.56481946  21.58414534]\n",
      "[-10.23383823   0.61522758  21.6528382 ]\n",
      "[-10.26649941   0.65945688  21.71334797]\n",
      "[-10.30470668   0.58008787  21.66305389]\n",
      "[-10.3088831    0.63031289  21.72961359]\n",
      "[-10.3303773    0.650231    21.77586884]\n",
      "[-10.3550473    0.67474369  21.8273685 ]\n",
      "[-10.3833711    0.65359425  21.83019422]\n",
      "[-10.39901785   0.6311825   21.83568302]\n",
      "[-10.40651648   0.55297298  21.78740422]\n",
      "[-10.39098308   0.55299835  21.81023493]\n",
      "[-10.38438942   0.50944296  21.79123805]\n",
      "[-10.36988086   0.54057848  21.85002736]\n",
      "[-10.3747579    0.54906949  21.88637048]\n",
      "[-10.38508452   0.55116094  21.91407528]\n",
      "[-10.39658344   0.49318303  21.8872637 ]\n",
      "[-10.39041735   0.47620744  21.89840634]\n",
      "[-10.38533431   0.41859512  21.8681352 ]\n",
      "[-10.36772141   0.38229634  21.86320472]\n",
      "[-10.34938542   0.4292599   21.93665921]\n",
      "[-10.35668401   0.45116402  21.99145237]\n",
      "[-10.37369881   0.47703024  22.03821926]\n",
      "[-10.39646848   0.46681046  22.05048811]\n",
      "[-10.41172939   0.47354132  22.0810513 ]\n",
      "[-10.42768023   0.33196416  21.95988019]\n",
      "[-10.39581752   0.41608305  22.06394426]\n",
      "[-10.40512592   0.42771915  22.10195522]\n",
      "[-10.41913027   0.48934916  22.18855643]\n",
      "[-10.45193957   0.47121714  22.19476603]\n",
      "[-10.47163014   0.40734896  22.15801899]\n",
      "[-10.46844243   0.36896694  22.14559951]\n",
      "[-10.45810381   0.39954311  22.20363239]\n",
      "[-10.46541292   0.30620604  22.13917282]\n",
      "[-10.44479803   0.35658209  22.21626669]\n",
      "[-10.45161021   0.29174422  22.18336244]\n",
      "[-10.4403131    0.2801718   22.19612228]\n",
      "[-10.43298818   0.29799986  22.24056512]\n",
      "[-10.43807351   0.24537398  22.2109317 ]\n",
      "[-10.42814391   0.25470739  22.23862714]\n",
      "[-10.42749752   0.27028199  22.27709455]\n",
      "[-10.43566393   0.27201315  22.3071487 ]\n",
      "[-10.44604621   0.27394896  22.34487131]\n",
      "[-10.45912159   0.29416948  22.3843488 ]\n",
      "[-10.47721735   0.22384665  22.3370831 ]\n",
      "[-10.47028074   0.25111278  22.38562665]\n",
      "[-10.47777752   0.25336203  22.41144093]\n",
      "[-10.48713486   0.18846857  22.38035904]\n",
      "[-10.47784135   0.18195649  22.40019965]\n",
      "[-10.47376783   0.21946298  22.45406087]\n",
      "[-10.48563929   0.19114641  22.45234713]\n",
      "[-10.48859694   0.16092886  22.43808548]\n",
      "[-10.48337949   0.11080143  22.41487282]\n",
      "[-10.46808727   0.15559575  22.48072116]\n",
      "[-10.47566488   0.12035818  22.47483395]\n",
      "[-10.47399493   0.18550542  22.56493796]\n",
      "[-10.49758213   0.13589863  22.54488229]\n",
      "[-10.50197734   0.11672684  22.55177167]\n",
      "[-10.502836     0.20060086  22.65628195]\n",
      "[-10.53330731   0.18513721  22.66855521]\n",
      "[-10.55288812   0.22139402  22.73540108]\n",
      "[-10.58208752   0.22207851  22.76011125]\n",
      "[-10.60538436   0.18821037  22.75874017]\n",
      "[-10.61514241   0.20766363  22.80615972]\n",
      "[-10.6321163    0.26854212  22.89698822]\n",
      "[-10.66720629   0.22971201  22.88202371]\n",
      "[-10.68196931   0.30237986  22.97375387]\n",
      "[-10.71758356   0.26916094  22.97080828]\n",
      "[-10.73550316   0.26583097  22.99375074]\n",
      "[-10.75042479   0.22346912  22.97685748]\n",
      "[-10.75091907   0.18064059  22.95851525]\n",
      "[-10.74149227   0.15881283  22.96248525]\n",
      "[-10.73232478   0.14668796  22.98124715]\n",
      "[-10.72719552   0.14649761  23.0058744 ]\n",
      "[-10.7275806    0.15858371  23.04639767]\n",
      "[-10.73605803   0.17578084  23.08285992]\n",
      "[-10.75008981   0.24585936  23.17374154]\n",
      "[-10.7846077    0.11994583  23.07856385]\n",
      "[-10.77270992   0.08113985  23.0712537 ]\n",
      "[-10.75740554   0.16671098  23.1773369 ]\n",
      "[-10.77739742   0.2428754   23.2812805 ]\n",
      "[-10.81878294   0.21200411  23.28072055]\n",
      "[-10.84141016   0.2070137   23.29792521]\n",
      "[-10.85834584   0.18975077  23.29929369]\n",
      "[-10.86709395   0.2357778   23.36891315]\n",
      "[-10.89093961   0.13095552  23.28944169]\n",
      "[-10.87787558   0.17644601  23.35114225]\n",
      "[-10.88595884   0.22567376  23.4152253 ]\n",
      "[-10.9090124    0.22342826  23.43479807]\n",
      "[-10.92705156   0.24946968  23.48797501]\n",
      "[-10.95136166   0.2835271   23.53983901]\n",
      "[-10.98091518   0.21753031  23.49806024]\n",
      "[-10.98384728   0.31912756  23.61906756]\n",
      "[-11.02031507   0.28002796  23.60845049]\n",
      "[-11.0369828    0.29903924  23.64992753]\n",
      "[-11.05746247   0.23484703  23.60447071]\n",
      "[-11.05408437   0.20787554  23.60956649]\n",
      "[-11.0483134    0.19852208  23.62701663]\n",
      "[-11.04563296   0.17779384  23.63429876]\n",
      "[-11.04165649   0.17097817  23.65766411]\n",
      "[-11.04148397   0.0844941   23.6008118 ]\n",
      "[-11.0188648    0.1124506   23.64948175]\n",
      "[-11.01567445   0.08845004  23.64198848]\n",
      "[-11.00857009   0.14329908  23.72123144]\n",
      "[-11.02463226   0.21933553  23.8205781 ]\n",
      "[-11.06244332   0.1910495   23.81933831]\n",
      "[-11.08319507   0.26600075  23.91444558]\n",
      "[-11.12326146   0.33470319  24.00123681]\n",
      "[-11.17396768   0.29538581  23.99162759]\n",
      "[-11.2005661    0.29326041  24.01486751]\n",
      "[-11.22164032   0.2770257   24.02253293]\n",
      "[-11.23443729   0.21738215  23.98978229]\n",
      "[-11.22870262   0.23434869  24.03595155]\n",
      "[-11.2345118    0.22403171  24.05025215]\n",
      "[-11.23895967   0.23449217  24.08138771]\n",
      "[-11.24829981   0.33235705  24.20155285]\n",
      "[-11.28790404   0.35043277  24.24839735]\n",
      "[-11.32445689   0.38095544  24.30238651]\n",
      "[-11.36194544   0.35998219  24.30433162]\n",
      "[-11.38433769   0.36266308  24.33503036]\n",
      "[-11.40447882   0.32930851  24.32541564]\n",
      "[-11.41146155   0.40039523  24.41809342]\n",
      "[-11.44105785   0.35735318  24.39838354]\n",
      "[-11.45147891   0.41046537  24.46705896]\n",
      "[-11.47700336   0.34111707  24.42493993]\n",
      "[-11.47723651   0.35042676  24.4483531 ]\n",
      "[-11.48234703   0.4027648   24.52520079]\n",
      "[-11.50537239   0.31515489  24.46375039]\n",
      "[-11.4981914    0.35493025  24.53083541]\n",
      "[-11.509545     0.21219951  24.41637466]\n",
      "[-11.47777032   0.23911716  24.46542971]\n",
      "[-11.46791725   0.2825485   24.52996589]\n",
      "[-11.47768495   0.33517576  24.60783613]\n",
      "[-11.50403622   0.31628606  24.61746306]\n",
      "[-11.52041607   0.321153    24.65176751]\n",
      "[-11.53737288   0.36151164  24.71573232]\n",
      "[-11.56458262   0.30402237  24.68061345]\n",
      "[-11.56896225   0.38751492  24.7867008 ]\n",
      "[-11.60052144   0.41245922  24.83227444]\n",
      "[-11.63252592   0.38644361  24.83238151]\n",
      "[-11.65032504   0.39384468  24.87353643]\n",
      "[-11.66964436   0.39669702  24.90516732]\n",
      "[-11.6878943    0.46631643  24.99372059]\n",
      "[-11.72397538   0.39769038  24.95028979]\n",
      "[-11.7316857    0.4362653   25.01411781]\n",
      "[-11.75225039   0.43237556  25.02877384]\n",
      "[-11.76782926   0.4518482   25.07286103]\n",
      "[-11.78790425   0.41094385  25.06225946]\n",
      "[-11.79377829   0.46773187  25.14922341]\n",
      "[-11.81922198   0.51112579  25.22215191]\n",
      "[-11.8538377    0.53032186  25.26440935]\n",
      "[-11.8865809    0.44442984  25.20162804]\n",
      "[-11.88672048   0.42815525  25.21333611]\n",
      "[-11.8860485    0.42500879  25.23995679]\n",
      "Epochs: 999 Weights:  [-11.88902078   0.40936196  25.24873539]\n",
      "y_fail: 15.78045075762465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-11.88902078,   0.40936196,  25.24873539])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = fit_stoch(Z, y, verbose=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored weights [-0.5722185317510287, -1.1456492800366263e-07, 0.00018825301204819278]\n",
      "Weights with y set to 1 [-3039.624840661464, -0.0006085688975554558, 1.0]\n"
     ]
    }
   ],
   "source": [
    "w = [w[i] / maxima[i] for i in range(len(w))]\n",
    "print(\"Restored weights\", w)\n",
    "w = [w[j] / w[-1] for j in range(len(w))]\n",
    "print(\"Weights with y set to 1\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_fr, y_fr, color='red')\n",
    "plt.scatter(x_en, y_en, color='blue')\n",
    "plt.plot([min(x_fr + x_en), max(x_fr + x_en)],\n",
    "         [-w[1] * min(x_fr + x_en) - w[0], -w[1] * max(x_fr + x_en) - w[0]], color='green')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "#plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Evaluate your logistic regression using the leave-one-out cross validation method as with the perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-814-a5ef76428430>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-814-a5ef76428430>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    w_train = #fit_stoch(X_train, y_train)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "def leave_one_out_cross_val(X, y, fitting_function):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    b = 0\n",
    "    evaluate = 0\n",
    "\n",
    "    num = int(np.array(X).shape[0])\n",
    "\n",
    "    for i,x in enumerate(X_norm):\n",
    "        for nbr in X_norm:\n",
    "            if nbr == x:\n",
    "                X_test = [nbr]\n",
    "                y_test = [y[i]]\n",
    "                continue\n",
    "            X_train.append(nbr)\n",
    "            y_train.append(y[i])\n",
    "        w_train = #fit_stoch(X_train, y_train)\n",
    "        y_pred = predict3(X_test, w_train)\n",
    "        evaluate += accuracy(y_test, y_pred)\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "\n",
    "    print(evaluate/len(X_norm))\n",
    "    \n",
    "    return evaluate/len(X_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 999 Weights:  [-5.80296176 -3.10204095 -2.97965323]\n",
      "y_fail: 0.007326903343542449\n",
      "Epochs: 999 Weights:  [-5.82942684 -3.07959431 -2.95520111]\n",
      "y_fail: 0.007337499403464686\n",
      "Epochs: 999 Weights:  [-5.71714745 -3.10789779 -2.98029485]\n",
      "y_fail: 0.007168143601904258\n",
      "Epochs: 999 Weights:  [-5.80060704 -3.10855738 -2.98315608]\n",
      "y_fail: 0.0073233075602136275\n",
      "Epochs: 999 Weights:  [-5.78030473 -3.11872672 -2.99333236]\n",
      "y_fail: 0.007305918724399132\n",
      "Epochs: 999 Weights:  [-5.81282005 -3.10121068 -2.97710672]\n",
      "y_fail: 0.007331118965667226\n",
      "Epochs: 999 Weights:  [-5.86554958 -3.03896969 -2.91970247]\n",
      "y_fail: 0.007363700640583682\n",
      "Epochs: 999 Weights:  [-5.80052444 -3.11299622 -2.98929296]\n",
      "y_fail: 0.007327344442840786\n",
      "Epochs: 999 Weights:  [-5.78436058 -3.11984605 -2.99311754]\n",
      "y_fail: 0.007311200583217308\n",
      "Epochs: 999 Weights:  [-5.76224737 -3.12438719 -2.99607051]\n",
      "y_fail: 0.007287507149177475\n",
      "Epochs: 999 Weights:  [-5.80317042 -3.10841094 -2.9828235 ]\n",
      "y_fail: 0.0073236544977594905\n",
      "Epochs: 999 Weights:  [-5.82124558 -3.08525533 -2.96014892]\n",
      "y_fail: 0.007341344342237567\n",
      "Epochs: 999 Weights:  [-5.85287583 -3.05660123 -2.93908263]\n",
      "y_fail: 0.0073632624210258095\n",
      "Epochs: 999 Weights:  [-5.86448028 -3.03952777 -2.91935471]\n",
      "y_fail: 0.007371338925914513\n",
      "Epochs: 999 Weights:  [-5.72882919 -3.11831244 -2.9932181 ]\n",
      "y_fail: 0.007200258969134829\n",
      "Epochs: 999 Weights:  [5.80905667 3.10407388 2.97513356]\n",
      "y_fail: 0.0073270502919511316\n",
      "Epochs: 999 Weights:  [5.82007167 3.10229632 2.97083722]\n",
      "y_fail: 0.007330422320452112\n",
      "Epochs: 999 Weights:  [5.71971158 3.11211298 2.98414035]\n",
      "y_fail: 0.007180106706574874\n",
      "Epochs: 999 Weights:  [5.80558584 3.11013799 2.97901279]\n",
      "y_fail: 0.0073220993249515365\n",
      "Epochs: 999 Weights:  [5.78190784 3.12402478 2.99512725]\n",
      "y_fail: 0.00730449650976972\n",
      "Epochs: 999 Weights:  [5.82265199 3.09097745 2.95977327]\n",
      "y_fail: 0.007341690371460596\n",
      "Epochs: 999 Weights:  [5.86483822 3.04405208 2.91615113]\n",
      "y_fail: 0.007366039448721495\n",
      "Epochs: 999 Weights:  [5.81449101 3.1016489  2.96799405]\n",
      "y_fail: 0.0073275367207845665\n",
      "Epochs: 999 Weights:  [5.79759227 3.10470402 2.97524199]\n",
      "y_fail: 0.007313039137354926\n",
      "Epochs: 999 Weights:  [5.76948889 3.12463506 2.99319461]\n",
      "y_fail: 0.007290464086663451\n",
      "Epochs: 999 Weights:  [5.81458119 3.10064275 2.96799744]\n",
      "y_fail: 0.007327856939495114\n",
      "Epochs: 999 Weights:  [5.81494512 3.10138462 2.97135   ]\n",
      "y_fail: 0.007341051176529612\n",
      "Epochs: 999 Weights:  [5.86691549 3.04115823 2.91123152]\n",
      "y_fail: 0.007369592479313458\n",
      "Epochs: 999 Weights:  [5.87647168 3.02801669 2.89434225]\n",
      "y_fail: 0.007375332759712916\n",
      "Epochs: 999 Weights:  [5.73801333 3.11070501 2.98322061]\n",
      "y_fail: 0.007230011315425\n",
      "0.0\n",
      "Cross-validation accuracy (batch): 0.0\n"
     ]
    }
   ],
   "source": [
    "stoch_accuracy = leave_one_out_cross_val(X, y, fit_stoch)\n",
    "print('Cross-validation accuracy (batch):', stoch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the logistic surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logistic_surf(x_range, y_range, w_opt):\n",
    "    z_axis = np.array([[0.0] * len(y_range) for i in range(len(x_range))])\n",
    "    x_axis, y_axis = np.meshgrid(x_range, y_range)\n",
    "    z_axis = z_axis.reshape(x_axis.shape)\n",
    "\n",
    "    # We compute the probability surface as a function of x and y\n",
    "    for i in range(len(x_range)):\n",
    "        for j in range(len(y_range)):\n",
    "            z_axis[j, i] = logistic(np.dot([1, x_range[i], y_range[j]], w_opt))\n",
    "    return x_axis, y_axis, z_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "logistic() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-741-1c95ec30998b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#w = [2.073225839414742, -0.049125455233437906, 0.7440143556104162]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_logistic_surf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-740-b25310896f04>\u001b[0m in \u001b[0;36mplot_logistic_surf\u001b[0;34m(x_range, y_range, w_opt)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mz_axis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: logistic() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "x_range = np.linspace(0, 100000, 200)\n",
    "y_range = np.linspace(0, 10000, 200)\n",
    "#w = [2.073225839414742, -0.049125455233437906, 0.7440143556104162]\n",
    "\n",
    "x_axis, y_axis, z_axis = plot_logistic_surf(x_range, y_range, w)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "# ax = fig.gca(projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(y_axis, x_axis, z_axis, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False, alpha=0.2)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "# We plot the observations\n",
    "for x, y_class in zip(X, y):\n",
    "    if y_class == 1:\n",
    "        ax.scatter(x[2], x[1], y_class, color='green', marker='x')\n",
    "    else:\n",
    "        ax.scatter(x[2], x[1], y_class, color='red', marker='x')\n",
    "\n",
    "ax.elev = 30 \n",
    "ax.azim = -150\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming logistic regression with popular APIs\n",
    "Should you use logistic regression in a project, you will probably resort to existing libraries. In the next cells, you will apply the logistic regression classification with two popular APIs:\n",
    "1. sklearn\n",
    "2. Keras\n",
    "\n",
    "`sklearn` is included in anaconda.\n",
    "You will install the rest with:\n",
    "```\n",
    "pip install --upgrade keras tensorflow tensorflow-addons \n",
    "```\n",
    "You will read and run the code in the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these APIs are built on numpy and we convert the dataset into numpy if you have not done it already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X_norm = np.array(X_norm)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They also handle the intercept so we do not need the first column of ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, 1:]\n",
    "X_norm = X_norm[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn\n",
    "Using the dataset of English and French datapoints, we apply logistic regression with the sklearn API. We need the `LogisticRegression` class, the fit() and predict() functions. The weights are in the `coef_` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03372363,  0.51169867]])"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model = model.fit(X, y)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the classes of the $\\mathbf{X}$ with the `predict()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the class probabilities of the $\\mathbf{X}$ with the `predict_proba()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.28980319e-30],\n",
       "       [9.99999999e-01, 8.16295157e-10],\n",
       "       [9.91302434e-01, 8.69756611e-03],\n",
       "       [1.00000000e+00, 2.35657080e-12],\n",
       "       [1.00000000e+00, 1.01085544e-22],\n",
       "       [1.00000000e+00, 3.56287478e-11],\n",
       "       [1.00000000e+00, 1.62389438e-24],\n",
       "       [1.00000000e+00, 5.76610689e-17],\n",
       "       [1.00000000e+00, 2.72458519e-12],\n",
       "       [9.94843591e-01, 5.15640906e-03],\n",
       "       [9.89714656e-01, 1.02853437e-02],\n",
       "       [1.00000000e+00, 4.22127774e-11],\n",
       "       [1.00000000e+00, 1.22665951e-41],\n",
       "       [1.00000000e+00, 7.37721442e-22],\n",
       "       [1.00000000e+00, 3.90177203e-16],\n",
       "       [1.33226763e-15, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.92390717e-02, 9.80760928e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.01629571e-09, 9.99999999e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.80182968e-02, 9.81981703e-01]])"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "Using the dataset of English and French datapoints, we apply logistic regression with Keras. We need the `Sequential` and `Dense` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.1-cp38-cp38-macosx_10_11_x86_64.whl (173.9 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173.9 MB 679 bytes/s a 0:00:01     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 103.2 MB 99.0 MB/s eta 0:00:01     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 165.7 MB 83.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /Users/AntonCarlsson/Library/Python/3.8/lib/python/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127 kB 27.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-macosx_10_9_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.6 MB 9.9 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.14.0-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.0 MB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.6 MB 18.9 MB/s eta 0:00:01    |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 4.6 MB 18.9 MB/s eta 0:00:01     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 6.2 MB 18.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.20.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (41.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96 kB 6.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 462 kB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=831ed85eb519d430ef50e1c017af23677182f8ce6b510b9eeea18445a3c12ccc\n",
      "  Stored in directory: /Users/AntonCarlsson/Library/Caches/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: six, wheel, werkzeug, tensorboard-plugin-wit, protobuf, numpy, markdown, grpcio, absl-py, typing-extensions, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.13.0\n",
      "    Uninstalling six-1.13.0:\n",
      "      Successfully uninstalled six-1.13.0\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.33.6\n",
      "    Uninstalling wheel-0.33.6:\n",
      "      Successfully uninstalled wheel-0.33.6\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.17.4\n",
      "    Uninstalling numpy-1.17.4:\n",
      "      Successfully uninstalled numpy-1.17.4\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.3.3 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.19.5 opt-einsum-3.3.0 protobuf-3.14.0 six-1.15.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 werkzeug-1.0.1 wheel-0.36.2\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e362880>"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=1500, batch_size=4, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.1948578e-29],\n",
       "       [2.2492475e-09],\n",
       "       [1.0871083e-02],\n",
       "       [9.5641706e-12],\n",
       "       [1.7264166e-21],\n",
       "       [1.1964309e-10],\n",
       "       [2.7048034e-23],\n",
       "       [4.3135981e-16],\n",
       "       [1.1247357e-11],\n",
       "       [6.2795579e-03],\n",
       "       [1.1236936e-02],\n",
       "       [1.4093961e-10],\n",
       "       [0.0000000e+00],\n",
       "       [8.5315004e-21],\n",
       "       [2.9307664e-15],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.7450966e-01],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.7565508e-01]], dtype=float32)"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not obtain a correct classification, rerun the training with more epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading\n",
    "You will read the article *An overview of gradient descent optimization algorithms* by Ruder (2017) and you will outline the main characteristics of all the optimization algorithms the author describes. This part should be of about one to two pages. Link to the article: https://arxiv.org/abs/1609.04747\n",
    "\n",
    "If you understand French, or using Google translate, you may also want to read the original article on gradient descent by Cauchy here:  https://gallica.bnf.fr/ark:/12148/bpt6k2982c/f540.item.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report\n",
    "\n",
    "The assignment must be documented in the report, which should contain the following:\n",
    "\n",
    "*   The name of the author, the title of the assignment, and any relevant information on the front page;\n",
    "*   A presentation of the assignment and the possible improvements you would have brought;\n",
    "*   A presentation of your implementation;\n",
    "*   A print-out of the example set(s) and the resulting weight vectors;\n",
    "*   Comments on the results you have obtained, including your cross validation;\n",
    "*   A short dissertation on the optimization algorithms from Ruder's paper.\n",
    "\n",
    "Please, typeset and format your report consistently. You must use Latex. Documents written using MS Word or any similar format will not be considered.\n",
    "\n",
    "You may have a look at the code in the textbook code repository (or any other implementations), but the code you hand in must be your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Submit the notebook and the report to Canvas (two files). Do not include the code printout in the report, but only comments on its interesting parts. You will submit the notebook as a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
